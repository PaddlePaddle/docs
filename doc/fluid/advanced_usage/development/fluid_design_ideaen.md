# an Overlook of Design

## Introduction

This document mainly introduces the design ideas of the bottom layer of Fluid to help users better understand the operation process of the framework.

Read this document and you will learn about:

- Fluid internal execution process
- How the program describe the model
- How the executor perform operations


## 1. Fluid internal execution process

Fluid uses a compiler-style execution flow, which is divided into compile-time and runtime components, including: compiler definition Program, create Executor to run Program.

The flow chart of the local training task execution is as follows:
<p align="center">
<img src="https://raw.githubusercontent.com/PaddlePaddle/FluidDoc/develop/doc/fluid/advanced_usage/design_idea/image/fluid_process.png" width=800>
</p>

 1. At compile time, the user writes a python program that adds variables (Tensor) and operations on variables (Operators or Layers) to a program by calling the operator provided by Fluid. Users only need to describe the core forward calculations, and do not need to care about reverse computing, distributed computing, and how to calculate under heterogeneous devices.

 2. The original Program is converted to an intermediate description language within the platform: `ProgramDesc`.

 3. One of the most important functional modules at compile time is `Transpiler`. `Transpiler` accepts a `ProgramDesc` and outputs a changed `ProgramDesc` as the backend `Executor` which ultimately needs to be executed.

 4. The backend Executor accepts the Program output by Transpiler, and executes the Operator in it (which can be analogized to the instructions in the programming language). During the execution, it creates the required input and output for the Operator and manages it.




## 2. Program design ideas

After the user completes the network definition, there are usually 2 programs in a Fluid program:

  1. fluid.default_startup_program: defines various operations such as creating model parameters, input and output, and initialization of learnable parameters in the model.

    default_startup_program can be automatically generated by the framework and created without display

    If the call changes the default initialization mode of the parameter, the framework will automatically add the relevant changes to the default_startup_program

  2. fluid.default_main_program: defines the neural network model, forward and backward calculations, and updates to the learnable parameters of the network by the optimization algorithm.

    The core of using Fluid is to build default_main_program



### Programs and Blocks
The basic structure of Fluid's Program is some nested blocks that are similar in form to a C++ or Java program.

The blocks contain:

- Definition of local variables
- A series of operators

The concept of block is consistent with a generic program, such as three blocks in the following C++ code:

``` cpp
int main(){ //block 0
int i = 0;
if (i<10){ //block 1
for (int j=0;j<10;j++){ //block 2
}
}
return 0;
}
```

Similarly, the following Fluid's Program contains 3 segments:

```python
import paddle.fluid as fluid # block 0

limit = fluid.layers.fill_constant_batch_size_like(
	Input=label, dtype='int64', shape=[1], value=5.0)
cond = fluid.layers.less_than(x=label, y=limit)

ie = fluid.layers.IfElse(cond)
with ie.true_block(): # block 1
	true_image = ie.input(image)
	hidden = fluid.layers.fc(input=true_image, size=100, act='tanh')
	prob = fluid.layers.fc(input=hidden, size=10, act='softmax')
	ie.output(prob)

with ie.false_block(): # block 2
	false_image = ie.input(image)
	hidden = fluid.layers.fc(
		input=false_image, size=200, act='tanh')
	prob = fluid.layers.fc(input=hidden, size=10, act='softmax')
	ie.output(prob)

prob = ie()
```
### BlockDesc and ProgramDesc

The block and program information described by the user is saved in Fluid in [protobuf](https://en.wikipedia.org/wiki/Protocol_Buffers) format, and all `protobub` information is defined in `framework.proto`, in Fluid It is called BlockDesc and ProgramDesc. The concepts of ProgramDesc and BlockDesc are similar to an [abstract syntax tree](https://en.wikipedia.org/wiki/Abstract_syntax_tree).

`BlockDesc` contains the definition of the local variable `vars`, and a series of operator`ops`:

```cpp
 message BlockDesc {
  required int32 parent = 1;
  repeated VarDesc vars = 2;
  repeated OpDesc ??ops = 3;
}
```
The parent ID represents the parent block, so the operators in the block can reference locally defined variables or refer to variables defined in the ancestor block.

Each block in the Program is flattened and stored in an array. The blocks ID is the index of the block in this array.

```cpp
message ProgramDesc {
  repeated BlockDesc blocks = 1;
}
```

### Using the Blocks Operator

In the example of [Programs and Blocks](#Programs and Blocks), the IfElseOp operator contains two blocks -- the true branch and the false branch.

The following ObDesc definition process describes which attributes an operator can contain:

```cpp
message OpDesc {
  AttrDesc attrs = 1;
  ...
}
```
The attribute can be the type of block, which is actually the block ID described above:
```cpp
message AttrDesc {
  required string name = 1;

  enum AttrType {
	INT = 1,
	STRING = 2,
	...
	BLOCK = ...
  }
  required AttrType type = 2;

  optional int32 block = 10; // when type == BLOCK
  ...
}
```
<a name="Executor Design Ideas"></a>
## 3. Executor design ideas

Executor will accept a `ProgramDesc`, a `block_id` and a `Scope` at runtime. `ProgramDesc` is a list of `block`, each containing all the parameters in `block` and the `protobuf` definition of `operator`; `block_id` specifying the entry block; `Scope` is the container for all variable instances.

The specific process of the completed compilation execution is shown in the following figure:

<p align="center">
<img src="https://raw.githubusercontent.com/PaddlePaddle/FluidDoc/develop/doc/fluid/advanced_usage/design_idea/image/executor_design.png" width=600>
</p>

1. Executor creates a Scope for each block, Block is nestable, so Scope is nestable
2. Create variables in all scopes
3. Create and execute all operators in order




Executor's C++ implementation code is as follows:

```cpp
class Executor{
		public:
			void Run(const ProgramDesc& pdesc,
							scope* scope,
							int block_id) {
						auto& block = pdesc.Block(block_id);

						// Create all variables
						for (auto& var : block.AllVars())
								scope->Var(Var->Name());
						}

						// Create OP and execute in order
						for (auto& op_desc : block.AllOps()){
								auto op = CreateOp(*op_desc);
								op->Run(*local_scope, place_);
						}
			}
	};
```

**Create Executor**

Fluid uses Fluid.Executor(place) to create an Executor. The place attribute is defined by the user and represents where the program will execute.

The following example code creates an Executor that runs in the CPU:

```python
cpu=core.CPUPlace()
exe = fluid.Executor(cpu)
```

**Run Executor**

Fluid uses Executor.run to run the program. In the definition, the data is obtained through the feed mapping, and the result is obtained through fetch\_list:

```python
...
x = numpy.random.random(size=(10, 1)).astype('float32')
outs = exe.run(
		feed={'X': x},
		fetch_list=[loss.name])
```


## Code Instance
This section introduces you to how the above is implemented in your code through a simple linear regression example in the [Fluid Programming Guide](../../beginners_guide/programming_guide/programming_guide.html).

**Define Program**

You can freely define your own data and network structure. The defined results will be received as a Program by Fluid. The basic structure of Program is some blocks. The Program in this section contains only one block 0:

```python
#Load function library
import paddle.fluid as fluid #block 0
import numpy

# Define data
train_data=numpy.array([[1.0],[2.0],[3.0],[4.0]]).astype('float32')
y_true = numpy.array([[2.0],[4.0],[6.0],[8.0]]).astype('float32')
# Define the network
x = fluid.layers.data(name="x",shape=[1],dtype='float32')
y = fluid.layers.data(name="y",shape=[1],dtype='float32')
y_predict = fluid.layers.fc(input=x,size=1,act=None)
#definition loss function
cost = fluid.layers.square_error_cost(input=y_predict,label=y)
avg_cost = fluid.layers.mean(cost)
#defined optimization method
sgd_optimizer = fluid.optimizer.SGD(learning_rate=0.01)
sgd_optimizer.minimize(avg_cost)
```

The above definition is completed, that is, the construction process of fluid.default_main_program is completed. Fluid.default_main_program carries the neural network model, forward and backward calculation, and the optimization algorithm updates the learnable parameters in the network.

At this point you can output this Program to observe the defined network form:
```python
print(fluid.default_main_program().to_string(True))
```
The complete ProgramDesc can be viewed locally. The results of the first three variables in this excerpt are as follows:
```
blocks {
  idx: 0
  parent_idx: -1
  vars {
	name: "mean_1.tmp_0"
	type {
	  type: LOD_TENSOR
	  lod_tensor {
		tensor {
		  data_type: FP32
		  dims: 1
		}
	  }
	}
	persistable: false
  }
  vars {
	name: "square_error_cost_1.tmp_1"
	type {
	  type: LOD_TENSOR
	  lod_tensor {
		tensor {
		  data_type: FP32
		  dims: -1
		  dims: 1
		}
		lod_level: 0
	  }
	}
	persistable: false
  }
  vars {
	name: "square_error_cost_1.tmp_0"
	type {
	  type: LOD_TENSOR
	  lod_tensor {
 		tensor {
		data_type: FP32
		  dims: -1
		  dims: 1
		}
		lod_level: 0
	  }
	}
	persistable: false
	...
```
As you can see from the output, the entire definition process is transformed into a ProgramDesc inside the framework, indexed by block idx. There is only one block in this linear regression model, and only Block 0 is a block Desc in the ProgramDesc.

BlockDesc contains defined vars and a series of ops. Take input x as an example. In python code, x is a 1D data of data type "float 32":
```python
x = fluid.layers.data(name="x",shape=[1],dtype='float32')
```
In BlockDesc, the variable x is described as:
```
vars {
	name: "x"
	type {
	  type: LOD_TENSOR
	  lod_tensor {
		tensor {
		  data_type: FP32
		  dims: -1
		  dims: 1
		}
		lod_level: 0
	  }
	}
	persistable: false
```
All data types in Fluid are LoD-Tensor, and for data without sequence information (such as variable X here), lod_level=0.

Dims represents the dimension of the data, where x is the dimension of [-1,1], where -1 is the dimension of the batch. When the specific value cannot be determined, Fluid automatically uses the -1 placeholder.

The parameter `persistable` indicates whether the variable is a persistent variable throughout the training process.

**Create Executor**

Fluid uses Executor to perform network training. For details on Executor operation, please refer to [Executor Design Ideas](#Executor Design Ideas). As a user, there is actually no need to understand the internal mechanism.

To create an Executor, simply call fluid.Executor(place). Before that, please define a place variable based on the training site:
```python
 #Execute training in the CPU
 cpu = fluid.core.CPUPlace()
 #Create Executor
 exe = fluid.Executor(cpu)
```
**Run Executor**

Fluid uses Executor.run to run a program.

Before the network training is officially performed, parameter initialization must be performed first. Among them, defalut_startup_program defines various operations such as creating model parameters, input and output, and initialization of learnable parameters in the model.
```python
 #Parameter initialization
 exe.run(fluid.default_startup_program())
```
Since there are multiple columns of incoming and outgoing data, fluid defines the data transfer data through the feed mapping, and fetch_list takes the expected result:
```python
# Start training
 outs = exe.run(
 	 feed={'x':train_data,'y':y_true},
	 fetch_list=[y_predict.name,avg_cost.name])
```
The above code segment defines train_data to pass the x variable, y_true to pass the y variable, output the predicted value of y and the last round of cost.

The output is:
```
[array([[1.5248038],
	   [3.0496075],
	   [4.5744114],
	   [6.099215 ]], dtype=float32), array([1.6935859], dtype=float32)]
```

At this point, you have already understood the core concepts of the execution process inside Fluid. For more details on the use of the framework, please refer to the [User Guide](../../user_guides/index.html) related content, [Model Library](../. ./user_guides/models/index_cn.html
) also provides you with a wealth of model examples for reference.
