# 飞桨预测库昆仑XPU版安装及使用示例

在昆仑XPU硬件上常用的高性能预测库主要包括以下3个，分别适用不同的云边端场景：

| 名称               | 英文表示         | 适用场景                     | 语言支持 | 安装方式 |
| ------------------ | ---------------- | ---------------------------- | ---------------------------- |---------------------------- |
| 飞桨原生推理库     | Paddle Inference | 高性能服务器端、云端推理     | Python、C++ |Python版whl包下载或源码编译，C++版源码编译 |
| 飞桨服务化推理框架 | Paddle Serving   | 自动服务、模型管理等高阶功能 | Python、C++ | 源码编译 |
| 飞桨轻量化推理引擎 | Paddle Lite      | 移动端、物联网等             | Python、C++ | 源码编译 |

Paddle Inference 2.1版本的安装及使用方式，请[点击查看](https://paddleinference.paddlepaddle.org.cn/demo_tutorial/paddle_xpu_infer_cn.html)。

Paddle Serving 0.6.0版本的安装及使用方式，请[点击查看](https://github.com/PaddlePaddle/Serving/blob/develop/doc/BAIDU_KUNLUN_XPU_SERVING_CN.md)。

Paddle Lite 2.9版本的安装及使用方式，请[点击查看](https://paddlelite.paddlepaddle.org.cn/demo_guides/baidu_xpu.html)。
