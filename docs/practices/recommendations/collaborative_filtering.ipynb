{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 使用协同过滤实现电影推荐\n",
    "\n",
    "**作者：** [HUANGCHENGAI](https://github.com/HUANGCHENGAI) <br>\n",
    "**日期：** 2022.5 <br>\n",
    "**摘要：** 本案例使用飞桨框架实现推荐电影的协同过滤算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 一、介绍\n",
    "\n",
    "此示例演示使用[Movielens 数据集](https://www.kaggle.com/c/movielens-100k)基于 PaddlePaddle 2.3.0 向用户推荐电影的协作过滤算法。MovieLens 评级数据集列出了一组用户对一组电影的评分。目标是能够预测用户尚未观看的电影的收视率。然后，可以向用户推荐预测收视率最高的电影。\n",
    "\n",
    "模型中的步骤如下：\n",
    "\n",
    "    1.通过嵌入矩阵将用户 ID 映射到\"用户向量\"\n",
    "\n",
    "    2.通过嵌入矩阵将电影 ID 映射到\"电影载体\"\n",
    "\n",
    "    3.计算用户矢量和电影矢量之间的点产品，以获得用户和电影之间的匹配分数（预测评级）。\n",
    "\n",
    "    4.使用所有已知的用户电影对通过梯度下降训练嵌入。\n",
    "\n",
    "\n",
    "引用：\n",
    "\n",
    "+ [Item-based collaborative filtering recommendation algorithms](https://dl.acm.org/doi/pdf/10.1145/371920.372071)\n",
    "\n",
    "+ [Neural Collaborative Filtering](https://dl.acm.org/doi/pdf/10.1145/3038912.3052569)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 二、 环境设置\n",
    "\n",
    "本教程基于PaddlePaddle 2.3.0 编写，如果你的环境不是本版本，请先参考官网[安装](https://www.paddlepaddle.org.cn/install/quick) PaddlePaddle 2.3.0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.io import Dataset\n",
    "\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 三、数据集\n",
    "\n",
    "这个数据集（ml-latest-small）描述了[MovieLens](http://movielens.org)的五星评级和自由文本标记活动。它包含100836个收视率和3683个标签应用程序，涵盖9742部电影。这些数据由610名用户在1996年3月29日至2018年9月24日期间创建。\n",
    "\n",
    "该数据集于2018年9月26日生成，用户是随机选择的。所有选定的用户都对至少20部电影进行了评分。不包括人口统计信息。每个用户都由一个id表示，不提供其他信息。数据包含在文件中`links.csv`, `movies.csv`, `ratings.csv`以及`tags.csv`。\n",
    "\n",
    "**用户ID**\n",
    "\n",
    "MovieLens的用户是随机选择的\n",
    "\n",
    "**电影ID**\n",
    "\n",
    "数据集中只包含至少具有一个分级或标记的电影，这些电影id与MovieLens网站上使用的一致.。\n",
    "\n",
    "分级数据文件结构(ratings.csv)\n",
    "\n",
    "所有评级都包含在文件中`ratings.csv`. 文件头行后的每一行代表一个用户对一部电影的一个分级，格式如下：\n",
    "userId，movieId，rating，timestamp\n",
    "\n",
    "\n",
    "**标记数据文件结构(tags.csv)**\n",
    "\n",
    "文件中包含所有标记`tags.csv`. 文件头行后的每一行代表一个用户应用于一部电影的一个标记，格式如下：\n",
    "userId，movieId，tag，timestamp\n",
    "\n",
    "\n",
    "**电影数据文件结构(movies.csv)**\n",
    "\n",
    "格式如下：\n",
    "电影ID、片名、类型\n",
    "\n",
    "**链接数据文件结构(links.csv)**\n",
    "\n",
    "格式如下：\n",
    "电影ID，imdbId，tmdbId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget -O ml-latest-small.zip https://bj.bcebos.com/v1/ai-studio-online/e1686458bb494866ab51d5e2738a68387d2aa14f31164735ae601eda5c7bc938\\?responseContentDisposition\\=attachment%3B%20filename%3Dml-latest-small.zip\\&authorization\\=bce-auth-v1%2F0ef6765c1e494918bc0d4c3ca3e5c6d1%2F2021-03-01T12%3A21%3A46Z%2F-1%2F%2F6dddaaacf7aa37c7445d3100844c71f9dd09fe938627f3ac86d0621e3f420f92\n",
    "!unzip ./ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1 数据处理\n",
    "\n",
    "执行一些预处理，将用户和电影编码为整数指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 610, Number of Movies: 9724, Min rating: 0.5, Max rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "user_ids = df[\"userId\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "movie_ids = df[\"movieId\"].unique().tolist()\n",
    "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
    "df[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\n",
    "\n",
    "num_users = len(user2user_encoded)\n",
    "num_movies = len(movie_encoded2movie)\n",
    "df[\"rating\"] = df[\"rating\"].values.astype(np.float32)\n",
    "# 最小和最大额定值将在以后用于标准化额定值\n",
    "min_rating = min(df[\"rating\"])\n",
    "max_rating = max(df[\"rating\"])\n",
    "\n",
    "print(\n",
    "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
    "        num_users, num_movies, min_rating, max_rating\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2 准备训练和验证数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,) (1,)\n",
      "[ 431 4730] [0.8888889]\n",
      "[128, 2]\n",
      "[128, 1]\n",
      "[128, 2]\n",
      "[128, 1]\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=1, random_state=42)\n",
    "x = df[[\"user\", \"movie\"]].values\n",
    "# 规范化0和1之间的目标。使训练更容易。\n",
    "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "# 假设对90%的数据进行训练，对10%的数据进行验证。\n",
    "train_indices = int(0.9 * df.shape[0])\n",
    "x_train, x_val, y_train, y_val = (\n",
    "    x[:train_indices],\n",
    "    x[train_indices:],\n",
    "    y[:train_indices],\n",
    "    y[train_indices:],\n",
    ")\n",
    "y_train = y_train[: ,np.newaxis]\n",
    "y_val = y_val[: ,np.newaxis]\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n",
    "\n",
    "# 自定义数据集\n",
    "#映射式(map-style)数据集需要继承paddle.io.Dataset\n",
    "class SelfDefinedDataset(Dataset):\n",
    "    def __init__(self, data_x, data_y, mode = 'train'):\n",
    "        super().__init__()\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.mode = mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'predict':\n",
    "           return self.data_x[idx]\n",
    "        else:\n",
    "           return self.data_x[idx], self.data_y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "        \n",
    "traindataset = SelfDefinedDataset(x_train, y_train)\n",
    "for data, label in traindataset:\n",
    "    print(data.shape, label.shape)\n",
    "    print(data, label)\n",
    "    break\n",
    "train_loader = paddle.io.DataLoader(traindataset, batch_size = 128, shuffle = True)\n",
    "for batch_id, data in enumerate(train_loader()):\n",
    "    x_data = data[0]\n",
    "    y_data = data[1]\n",
    "\n",
    "    print(x_data.shape)\n",
    "    print(y_data.shape)\n",
    "    break\n",
    "\n",
    "testdataset = SelfDefinedDataset(x_val, y_val)\n",
    "test_loader = paddle.io.DataLoader(testdataset, batch_size = 128, shuffle = True)        \n",
    "for batch_id, data in enumerate(test_loader()):\n",
    "    x_data = data[0]\n",
    "    y_data = data[1]\n",
    "\n",
    "    print(x_data.shape)\n",
    "    print(y_data.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 四、模型组网\n",
    "\n",
    "将用户和电影嵌入到 50 维向量中。\n",
    "\n",
    "该模型计算用户和电影嵌入之间的匹配分数，并添加每部电影和每个用户的偏差。比赛分数通过 sigmoid 缩放到间隔[0, 1]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "class RecommenderNet(nn.Layer):\n",
    "    def __init__(self, num_users, num_movies, embedding_size):\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        weight_attr_user = paddle.ParamAttr(\n",
    "            regularizer = paddle.regularizer.L2Decay(1e-6),\n",
    "            initializer = nn.initializer.KaimingNormal()\n",
    "            )\n",
    "        self.user_embedding = nn.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            weight_attr=weight_attr_user\n",
    "        )\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        weight_attr_movie = paddle.ParamAttr(\n",
    "            regularizer = paddle.regularizer.L2Decay(1e-6),\n",
    "            initializer = nn.initializer.KaimingNormal()\n",
    "            )\n",
    "        self.movie_embedding = nn.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            weight_attr=weight_attr_movie\n",
    "        )\n",
    "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        dot_user_movie = paddle.dot(user_vector, movie_vector)\n",
    "        x = dot_user_movie + user_bias + movie_bias\n",
    "        x = nn.functional.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 五、模型训练\n",
    "\n",
    "后台可通过VisualDl观察Loss曲线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0509 17:19:27.996690   280 gpu_context.cc:278] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0509 17:19:28.001456   280 gpu_context.cc:306] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/5\n",
      "step  50/709 [=>............................] - loss: 0.6924 - acc: 0.8661 - ETA: 4s - 7ms/ste"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:278: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int64, but right dtype is paddle.float32, the right dtype will convert to paddle.int64\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100/709 [===>..........................] - loss: 0.6892 - acc: 0.8691 - ETA: 3s - 6ms/stepstep 250/709 [=========>....................] - loss: 0.6877 - acc: 0.8689 - ETA: 2s - 5ms/s\n",
      "step 709/709 [==============================] - loss: 0.6701 - acc: 0.8687 - 4ms/step         \n",
      "save checkpoint at /home/aistudio/checkpoints/0\n",
      "Epoch 2/5\n",
      "step 709/709 [==============================] - loss: 0.6650 - acc: 0.8687 - 4ms/step        \n",
      "save checkpoint at /home/aistudio/checkpoints/1\n",
      "Epoch 3/5\n",
      "step 709/709 [==============================] - loss: 0.6330 - acc: 0.8687 - 4ms/step        \n",
      "save checkpoint at /home/aistudio/checkpoints/2\n",
      "Epoch 4/5\n",
      "step 709/709 [==============================] - loss: 0.6216 - acc: 0.8687 - 4ms/step        \n",
      "save checkpoint at /home/aistudio/checkpoints/3\n",
      "Epoch 5/5\n",
      "step 709/709 [==============================] - loss: 0.5908 - acc: 0.8687 - 4ms/step        \n",
      "save checkpoint at /home/aistudio/checkpoints/4\n",
      "save checkpoint at /home/aistudio/checkpoints/final\n"
     ]
    }
   ],
   "source": [
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
    "model = paddle.Model(model)\n",
    "\n",
    "optimizer = paddle.optimizer.Adam(parameters=model.parameters(), learning_rate=0.0003)\n",
    "loss = nn.BCELoss()\n",
    "metric = paddle.metric.Accuracy()\n",
    "\n",
    "# 设置visualdl路径\n",
    "log_dir = './visualdl'\n",
    "callback = paddle.callbacks.VisualDL(log_dir=log_dir)\n",
    "\n",
    "model.prepare(optimizer, loss, metric)\n",
    "model.fit(train_loader, epochs=5, save_dir='./checkpoints', verbose=1, callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 六、模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step 79/79 [==============================] - loss: 0.5970 - acc: 0.8713 - 2ms/step         \n",
      "Eval samples: 10084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:278: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int64, but right dtype is paddle.float32, the right dtype will convert to paddle.int64\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.59696674], 'acc': 0.8712812376041253}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_loader, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 七、模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\n",
      "step 1/1 [==============================] - 22ms/step\n",
      "Predict samples: 8785\n",
      "[ 527 1829 1585  477  738  963 8014 1826  746  975]\n",
      "用户的ID为: 298\n",
      "================================\n",
      "用户评分较高的电影：\n",
      "--------------------------------\n",
      "Blade Runner (1982) : Action|Sci-Fi|Thriller\n",
      "Godfather, The (1972) : Crime|Drama\n",
      "Big Lebowski, The (1998) : Comedy|Crime\n",
      "Fight Club (1999) : Action|Crime|Drama|Thriller\n",
      "Indiana Jones and the Kingdom of the Crystal Skull (2008) : Action|Adventure|Comedy|Sci-Fi\n",
      "--------------------------------\n",
      "为用户推荐的10部电影：\n",
      "--------------------------------\n",
      "Schindler's List (1993) : Drama|War\n",
      "Silence of the Lambs, The (1991) : Crime|Horror|Thriller\n",
      "Rear Window (1954) : Mystery|Thriller\n",
      "Casablanca (1942) : Drama|Romance\n",
      "Lawrence of Arabia (1962) : Adventure|Drama|War\n",
      "Amadeus (1984) : Drama\n",
      "Saving Private Ryan (1998) : Action|Drama|War\n",
      "Life Is Beautiful (La Vita è bella) (1997) : Comedy|Drama|Romance|War\n",
      "American History X (1998) : Crime|Drama\n",
      "WALL·E (2008) : Adventure|Animation|Children|Romance|Sci-Fi\n"
     ]
    }
   ],
   "source": [
    "movie_df = pd.read_csv('ml-latest-small/movies.csv')\n",
    "\n",
    "# 获取一个用户，查看他的推荐电影\n",
    "user_id = df.userId.sample(1).iloc[0]\n",
    "movies_watched_by_user = df[df.userId == user_id]\n",
    "movies_not_watched = movie_df[\n",
    "    ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
    "][\"movieId\"]\n",
    "movies_not_watched = list(\n",
    "    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
    ")\n",
    "movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
    "user_encoder = user2user_encoded.get(user_id)\n",
    "user_movie_array = np.hstack(\n",
    "    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
    ")\n",
    "testdataset = SelfDefinedDataset(user_movie_array, user_movie_array, mode = 'predict')\n",
    "test_loader = paddle.io.DataLoader(testdataset, batch_size = 9703, shuffle = False, return_list=True,)   \n",
    "\n",
    "ratings = model.predict(test_loader)\n",
    "ratings = np.array(ratings)\n",
    "ratings = np.squeeze(ratings, 0)\n",
    "ratings = np.squeeze(ratings, 2)\n",
    "ratings = np.squeeze(ratings, 0)\n",
    "top_ratings_indices = ratings.argsort()[::-1][0:10]\n",
    "\n",
    "print(top_ratings_indices)\n",
    "recommended_movie_ids = [\n",
    "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
    "]\n",
    "\n",
    "print(\"用户的ID为: {}\".format(user_id))\n",
    "print(\"====\" * 8)\n",
    "print(\"用户评分较高的电影：\")\n",
    "print(\"----\" * 8)\n",
    "top_movies_user = (\n",
    "    movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
    "    .head(5)\n",
    "    .movieId.values\n",
    ")\n",
    "movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
    "for row in movie_df_rows.itertuples():\n",
    "    print(row.title, \":\", row.genres)\n",
    "\n",
    "print(\"----\" * 8)\n",
    "print(\"为用户推荐的10部电影：\")\n",
    "print(\"----\" * 8)\n",
    "recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
    "for row in recommended_movies.itertuples():\n",
    "    print(row.title, \":\", row.genres)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
