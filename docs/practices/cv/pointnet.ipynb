{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **点云处理：实现PointNet点云分类**\n",
    "**作者**：[Zhihao Cao](https://github.com/WhiteFireFox)<br>\n",
    "**日期**：2022.4<br>\n",
    "**摘要**：本示例在于演示如何基于 Paddle2.2 实现PointNet在ShapeNet数据集上进行点云分类处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 一、环境设置\n",
    "\n",
    "本教程基于PaddlePaddle 2.3.0-rc0 编写，如果你的环境不是本版本，请先参考官网[安装](https://www.paddlepaddle.org.cn/install/quick)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 二、数据集\n",
    "### 2.1 数据介绍\n",
    "ShapeNet数据集是一个注释丰富且规模较大的 3D 形状数据集，由斯坦福大学、普林斯顿大学和芝加哥丰田技术学院于 2015 年联合发布。<br>\n",
    "ShapeNet数据集官方链接：[https://vision.princeton.edu/projects/2014/3DShapeNets/](https://vision.princeton.edu/projects/2014/3DShapeNets/)<br>\n",
    "AIStudio链接：[sharpnet数据集(经过整理)](https://aistudio.baidu.com/aistudio/datasetdetail/70460)<br>\n",
    "ShapeNet数据集的储存格式是h5文件，该文件中key值分别为：\n",
    "- 1、data：这一份数据中所有点的xyz坐标，\n",
    "- 2、label：这一份数据所属类别，如airplane等，\n",
    "- 3、pid：这一份数据中所有点所属的类型，如这一份数据属airplane类，则它包含的所有点的类型有机翼、机身等类型。\n",
    "### 2.2 解压数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/data70460/shapenet_part_seg_hdf5_data.zip\n",
      "   creating: hdf5_data/\n",
      "  inflating: hdf5_data/ply_data_train5.h5  \n",
      "  inflating: hdf5_data/ply_data_train1.h5  \n",
      "  inflating: hdf5_data/ply_data_train3.h5  \n",
      "  inflating: hdf5_data/ply_data_val0.h5  \n",
      "  inflating: hdf5_data/ply_data_train0.h5  \n",
      "  inflating: hdf5_data/ply_data_test1.h5  \n",
      "  inflating: hdf5_data/ply_data_test0.h5  \n",
      "  inflating: hdf5_data/ply_data_train4.h5  \n",
      "  inflating: hdf5_data/ply_data_train2.h5  \n"
     ]
    }
   ],
   "source": [
    "!unzip data/data70460/shapenet_part_seg_hdf5_data.zip\r\n",
    "!mv hdf5_data dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.3 数据列表\n",
    "ShapeNet数据集所有的数据文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_list = ['ply_data_train0.h5', 'ply_data_train1.h5', 'ply_data_train2.h5', 'ply_data_train3.h5', 'ply_data_train4.h5', 'ply_data_train5.h5']\r\n",
    "test_list = ['ply_data_test0.h5', 'ply_data_test1.h5']\r\n",
    "val_list = ['ply_data_val0.h5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.4 搭建数据生成器\n",
    "说明：将ShapeNet数据集全部读入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_data(mode='train', path='./dataset/', num_point=2048):\r\n",
    "    datas = []\r\n",
    "    labels = []\r\n",
    "    if mode == 'train':\r\n",
    "        for file_list in train_list:\r\n",
    "            f = h5py.File(os.path.join(path, file_list), 'r')\r\n",
    "            datas.extend(f['data'][:, :num_point, :])\r\n",
    "            labels.extend(f['label'])\r\n",
    "            f.close()\r\n",
    "    elif mode == 'test':\r\n",
    "        for file_list in test_list:\r\n",
    "            f = h5py.File(os.path.join(path, file_list), 'r')\r\n",
    "            datas.extend(f['data'][:, :num_point, :])\r\n",
    "            labels.extend(f['label'])\r\n",
    "            f.close()\r\n",
    "    else:\r\n",
    "        for file_list in val_list:\r\n",
    "            f = h5py.File(os.path.join(path, file_list), 'r')\r\n",
    "            datas.extend(f['data'][:, :num_point, :])\r\n",
    "            labels.extend(f['label'])\r\n",
    "            f.close()\r\n",
    "    \r\n",
    "    return datas, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "说明：通过继承`paddle.io.Dataset`来完成数据集的构造。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PointDataset(paddle.io.Dataset):\r\n",
    "    def __init__(self, datas, labels):\r\n",
    "        super(PointDataset, self).__init__()\r\n",
    "        self.datas = datas\r\n",
    "        self.labels = labels\r\n",
    "    \r\n",
    "    def __getitem__(self, index):\r\n",
    "        data = paddle.to_tensor(self.datas[index].T.astype('float32'))\r\n",
    "        label = paddle.to_tensor(self.labels[index].astype('int64'))\r\n",
    "        return data, label\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "说明：使用飞桨框架提供的API：`paddle.io.DataLoader`完成数据的加载，使得按照Batchsize生成Mini-batch的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据导入\r\n",
    "datas, labels = make_data(mode='train', num_point=2048)\r\n",
    "train_dataset = PointDataset(datas, labels)\r\n",
    "datas, labels = make_data(mode='val', num_point=2048)\r\n",
    "val_dataset = PointDataset(datas, labels)\r\n",
    "datas, labels = make_data(mode='test', num_point=2048)\r\n",
    "test_dataset = PointDataset(datas, labels)\r\n",
    "\r\n",
    "# 实例化数据读取器\r\n",
    "train_loader = paddle.io.DataLoader(\r\n",
    "    train_dataset,\r\n",
    "    batch_size=128,\r\n",
    "    shuffle=True,\r\n",
    "    drop_last=False\r\n",
    ")\r\n",
    "val_loader = paddle.io.DataLoader(\r\n",
    "    val_dataset,\r\n",
    "    batch_size=32,\r\n",
    "    shuffle=False,\r\n",
    "    drop_last=False\r\n",
    ")\r\n",
    "test_loader = paddle.io.DataLoader(\r\n",
    "    test_dataset,\r\n",
    "    batch_size=128,\r\n",
    "    shuffle=False,\r\n",
    "    drop_last=False\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 三、定义网络\n",
    "PointNet是斯坦福大学研究人员提出的一个点云处理网络，在这篇论文中，它提出了空间变换网络（T-Net）解决点云的旋转问题（注：因为考虑到某一物体的点云旋转后还是该物体，所以需要有一个网络结构去学习并解决这个旋转问题），并且提出了采取MaxPooling的方法极大程度上地提取点云全局特征。\n",
    "\n",
    "### 3.1 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PointNet(nn.Layer):\r\n",
    "    def __init__(self, name_scope='PointNet_', num_classes=16, num_point=2048):\r\n",
    "        super(PointNet, self).__init__()\r\n",
    "        self.input_transform_net = nn.Sequential(\r\n",
    "            nn.Conv1D(3, 64, 1),\r\n",
    "            nn.BatchNorm(64),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv1D(64, 128, 1),\r\n",
    "            nn.BatchNorm(128),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv1D(128, 1024, 1),\r\n",
    "            nn.BatchNorm(1024),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool1D(num_point)\r\n",
    "        )\r\n",
    "        self.input_fc = nn.Sequential(\r\n",
    "            nn.Linear(1024, 512),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(512, 256),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(256, 9,\r\n",
    "                weight_attr=paddle.ParamAttr(initializer=paddle.nn.initializer.Assign(paddle.zeros((256, 9)))),\r\n",
    "                bias_attr=paddle.ParamAttr(initializer=paddle.nn.initializer.Assign(paddle.reshape(paddle.eye(3), [-1])))\r\n",
    "            )\r\n",
    "        )\r\n",
    "        self.mlp_1 = nn.Sequential(\r\n",
    "            nn.Conv1D(3, 64, 1),\r\n",
    "            nn.BatchNorm(64),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv1D(64, 64, 1),\r\n",
    "            nn.BatchNorm(64),\r\n",
    "            nn.ReLU()\r\n",
    "        )\r\n",
    "        self.feature_transform_net = nn.Sequential(\r\n",
    "            nn.Conv1D(64, 64, 1),\r\n",
    "            nn.BatchNorm(64),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv1D(64, 128, 1),\r\n",
    "            nn.BatchNorm(128),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv1D(128, 1024, 1),\r\n",
    "            nn.BatchNorm(1024),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool1D(num_point)\r\n",
    "        )\r\n",
    "        self.feature_fc = nn.Sequential(\r\n",
    "            nn.Linear(1024, 512),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(512, 256),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(256, 64*64)\r\n",
    "        )\r\n",
    "        self.mlp_2 = nn.Sequential(\r\n",
    "            nn.Conv1D(64, 64, 1),\r\n",
    "            nn.BatchNorm(64),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv1D(64, 128, 1),\r\n",
    "            nn.BatchNorm(128),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv1D(128, 1024, 1),\r\n",
    "            nn.BatchNorm(1024),\r\n",
    "            nn.ReLU()\r\n",
    "        )\r\n",
    "        self.fc = nn.Sequential(\r\n",
    "            nn.Linear(1024, 512),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(512, 256),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(p=0.7),\r\n",
    "            nn.Linear(256, num_classes),\r\n",
    "            nn.LogSoftmax(axis=-1)\r\n",
    "        )\r\n",
    "    def forward(self, inputs):\r\n",
    "        batchsize = inputs.shape[0]\r\n",
    "\r\n",
    "        t_net = self.input_transform_net(inputs)\r\n",
    "        t_net = paddle.squeeze(t_net, axis=-1)\r\n",
    "        t_net = self.input_fc(t_net)\r\n",
    "        t_net = paddle.reshape(t_net, [batchsize, 3, 3])\r\n",
    "\r\n",
    "        x = paddle.transpose(inputs, (0, 2, 1))\r\n",
    "        x = paddle.matmul(x, t_net)\r\n",
    "        x = paddle.transpose(x, (0, 2, 1))\r\n",
    "        x = self.mlp_1(x)\r\n",
    "\r\n",
    "        t_net = self.feature_transform_net(x)\r\n",
    "        t_net = paddle.squeeze(t_net, axis=-1)\r\n",
    "        t_net = self.feature_fc(t_net)\r\n",
    "        t_net = paddle.reshape(t_net, [batchsize, 64, 64])\r\n",
    "\r\n",
    "        x = paddle.squeeze(x, axis=-1)\r\n",
    "        x = paddle.transpose(x, (0, 2, 1))\r\n",
    "        x = paddle.matmul(x, t_net)\r\n",
    "        x = paddle.transpose(x, (0, 2, 1))\r\n",
    "        x = self.mlp_2(x)\r\n",
    "        x = paddle.max(x, axis=-1)\r\n",
    "        x = paddle.squeeze(x, axis=-1)\r\n",
    "        x = self.fc(x)\r\n",
    "\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2 网络结构可视化\n",
    "说明：使用飞桨API：`paddle.summary`完成模型结构可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0424 11:24:32.235721   117 gpu_context.cc:244] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0424 11:24:32.240563   117 gpu_context.cc:272] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "   Conv1D-1       [[64, 3, 2048]]       [64, 64, 2048]          256      \n",
      "  BatchNorm-1     [[64, 64, 2048]]      [64, 64, 2048]          256      \n",
      "    ReLU-1        [[64, 64, 2048]]      [64, 64, 2048]           0       \n",
      "   Conv1D-2       [[64, 64, 2048]]     [64, 128, 2048]         8,320     \n",
      "  BatchNorm-2    [[64, 128, 2048]]     [64, 128, 2048]          512      \n",
      "    ReLU-2       [[64, 128, 2048]]     [64, 128, 2048]           0       \n",
      "   Conv1D-3      [[64, 128, 2048]]     [64, 1024, 2048]       132,096    \n",
      "  BatchNorm-3    [[64, 1024, 2048]]    [64, 1024, 2048]        4,096     \n",
      "    ReLU-3       [[64, 1024, 2048]]    [64, 1024, 2048]          0       \n",
      "  MaxPool1D-1    [[64, 1024, 2048]]     [64, 1024, 1]            0       \n",
      "   Linear-1         [[64, 1024]]          [64, 512]           524,800    \n",
      "    ReLU-4          [[64, 512]]           [64, 512]              0       \n",
      "   Linear-2         [[64, 512]]           [64, 256]           131,328    \n",
      "    ReLU-5          [[64, 256]]           [64, 256]              0       \n",
      "   Linear-3         [[64, 256]]            [64, 9]             2,313     \n",
      "   Conv1D-4       [[64, 3, 2048]]       [64, 64, 2048]          256      \n",
      "  BatchNorm-4     [[64, 64, 2048]]      [64, 64, 2048]          256      \n",
      "    ReLU-6        [[64, 64, 2048]]      [64, 64, 2048]           0       \n",
      "   Conv1D-5       [[64, 64, 2048]]      [64, 64, 2048]         4,160     \n",
      "  BatchNorm-5     [[64, 64, 2048]]      [64, 64, 2048]          256      \n",
      "    ReLU-7        [[64, 64, 2048]]      [64, 64, 2048]           0       \n",
      "   Conv1D-6       [[64, 64, 2048]]      [64, 64, 2048]         4,160     \n",
      "  BatchNorm-6     [[64, 64, 2048]]      [64, 64, 2048]          256      \n",
      "    ReLU-8        [[64, 64, 2048]]      [64, 64, 2048]           0       \n",
      "   Conv1D-7       [[64, 64, 2048]]     [64, 128, 2048]         8,320     \n",
      "  BatchNorm-7    [[64, 128, 2048]]     [64, 128, 2048]          512      \n",
      "    ReLU-9       [[64, 128, 2048]]     [64, 128, 2048]           0       \n",
      "   Conv1D-8      [[64, 128, 2048]]     [64, 1024, 2048]       132,096    \n",
      "  BatchNorm-8    [[64, 1024, 2048]]    [64, 1024, 2048]        4,096     \n",
      "    ReLU-10      [[64, 1024, 2048]]    [64, 1024, 2048]          0       \n",
      "  MaxPool1D-2    [[64, 1024, 2048]]     [64, 1024, 1]            0       \n",
      "   Linear-4         [[64, 1024]]          [64, 512]           524,800    \n",
      "    ReLU-11         [[64, 512]]           [64, 512]              0       \n",
      "   Linear-5         [[64, 512]]           [64, 256]           131,328    \n",
      "    ReLU-12         [[64, 256]]           [64, 256]              0       \n",
      "   Linear-6         [[64, 256]]           [64, 4096]         1,052,672   \n",
      "   Conv1D-9       [[64, 64, 2048]]      [64, 64, 2048]         4,160     \n",
      "  BatchNorm-9     [[64, 64, 2048]]      [64, 64, 2048]          256      \n",
      "    ReLU-13       [[64, 64, 2048]]      [64, 64, 2048]           0       \n",
      "   Conv1D-10      [[64, 64, 2048]]     [64, 128, 2048]         8,320     \n",
      " BatchNorm-10    [[64, 128, 2048]]     [64, 128, 2048]          512      \n",
      "    ReLU-14      [[64, 128, 2048]]     [64, 128, 2048]           0       \n",
      "   Conv1D-11     [[64, 128, 2048]]     [64, 1024, 2048]       132,096    \n",
      " BatchNorm-11    [[64, 1024, 2048]]    [64, 1024, 2048]        4,096     \n",
      "    ReLU-15      [[64, 1024, 2048]]    [64, 1024, 2048]          0       \n",
      "   Linear-7         [[64, 1024]]          [64, 512]           524,800    \n",
      "    ReLU-16         [[64, 512]]           [64, 512]              0       \n",
      "   Linear-8         [[64, 512]]           [64, 256]           131,328    \n",
      "    ReLU-17         [[64, 256]]           [64, 256]              0       \n",
      "   Dropout-1        [[64, 256]]           [64, 256]              0       \n",
      "   Linear-9         [[64, 256]]            [64, 16]            4,112     \n",
      " LogSoftmax-1        [[64, 16]]            [64, 16]              0       \n",
      "===========================================================================\n",
      "Total params: 3,476,825\n",
      "Trainable params: 3,461,721\n",
      "Non-trainable params: 15,104\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 1.50\n",
      "Forward/backward pass size (MB): 11333.40\n",
      "Params size (MB): 13.26\n",
      "Estimated Total Size (MB): 11348.16\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 3476825, 'trainable_params': 3461721}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointnet = PointNet()\n",
    "paddle.summary(pointnet, (64, 3, 2048))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 四、训练\n",
    "说明：模型训练的时候，将会使用`paddle.optimizer.Adam`优化器来进行优化。使用`F.nll_loss`来计算损失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================train===========================================\n",
      "train: epoch: 0, batch_id: 0, loss is: [8.693383], accuracy is: [0.015625]\n",
      "train: epoch: 0, batch_id: 20, loss is: [1.2929151], accuracy is: [0.6015625]\n",
      "train: epoch: 0, batch_id: 40, loss is: [0.8927105], accuracy is: [0.75]\n",
      "train: epoch: 0, batch_id: 60, loss is: [0.7519456], accuracy is: [0.78125]\n",
      "train: epoch: 0, batch_id: 80, loss is: [0.66354436], accuracy is: [0.8359375]\n",
      "===================================val===========================================\n",
      "validation: loss is: 0.39304283261299133, accuracy is: 0.867584764957428\n",
      "===================================train===========================================\n",
      "train: epoch: 1, batch_id: 0, loss is: [0.66547674], accuracy is: [0.796875]\n",
      "train: epoch: 1, batch_id: 20, loss is: [0.5581873], accuracy is: [0.8125]\n",
      "train: epoch: 1, batch_id: 40, loss is: [0.4634911], accuracy is: [0.8515625]\n",
      "train: epoch: 1, batch_id: 60, loss is: [0.2632866], accuracy is: [0.8828125]\n",
      "train: epoch: 1, batch_id: 80, loss is: [0.32553214], accuracy is: [0.8828125]\n",
      "===================================val===========================================\n",
      "validation: loss is: 0.2947256565093994, accuracy is: 0.9020127058029175\n",
      "===================================train===========================================\n",
      "train: epoch: 2, batch_id: 0, loss is: [0.30400345], accuracy is: [0.90625]\n",
      "train: epoch: 2, batch_id: 20, loss is: [0.43601793], accuracy is: [0.875]\n",
      "train: epoch: 2, batch_id: 40, loss is: [0.34586048], accuracy is: [0.859375]\n",
      "train: epoch: 2, batch_id: 60, loss is: [0.35014084], accuracy is: [0.921875]\n",
      "train: epoch: 2, batch_id: 80, loss is: [0.30653465], accuracy is: [0.8828125]\n",
      "===================================val===========================================\n",
      "validation: loss is: 0.21731847524642944, accuracy is: 0.9385592937469482\n",
      "===================================train===========================================\n",
      "train: epoch: 3, batch_id: 0, loss is: [0.36968467], accuracy is: [0.875]\n",
      "train: epoch: 3, batch_id: 20, loss is: [0.37996972], accuracy is: [0.9140625]\n",
      "train: epoch: 3, batch_id: 40, loss is: [0.25406647], accuracy is: [0.921875]\n",
      "train: epoch: 3, batch_id: 60, loss is: [0.1649745], accuracy is: [0.953125]\n",
      "train: epoch: 3, batch_id: 80, loss is: [0.16395089], accuracy is: [0.9609375]\n",
      "===================================val===========================================\n",
      "validation: loss is: 0.26106956601142883, accuracy is: 0.9226694703102112\n",
      "===================================train===========================================\n",
      "train: epoch: 4, batch_id: 0, loss is: [0.17851768], accuracy is: [0.9453125]\n",
      "train: epoch: 4, batch_id: 20, loss is: [0.29574272], accuracy is: [0.9375]\n",
      "train: epoch: 4, batch_id: 40, loss is: [0.22927402], accuracy is: [0.9375]\n",
      "train: epoch: 4, batch_id: 60, loss is: [0.20726189], accuracy is: [0.9375]\n",
      "train: epoch: 4, batch_id: 80, loss is: [0.16911985], accuracy is: [0.9453125]\n",
      "===================================val===========================================\n",
      "validation: loss is: 0.11279569566249847, accuracy is: 0.9645127058029175\n",
      "===================================train===========================================\n",
      "train: epoch: 5, batch_id: 0, loss is: [0.27182847], accuracy is: [0.90625]\n",
      "train: epoch: 5, batch_id: 20, loss is: [0.1203089], accuracy is: [0.953125]\n",
      "train: epoch: 5, batch_id: 40, loss is: [0.25080964], accuracy is: [0.9140625]\n",
      "train: epoch: 5, batch_id: 60, loss is: [0.18479557], accuracy is: [0.96875]\n",
      "train: epoch: 5, batch_id: 80, loss is: [0.18184912], accuracy is: [0.9453125]\n",
      "===================================val===========================================\n",
      "validation: loss is: 0.5406728982925415, accuracy is: 0.8646337985992432\n",
      "===================================train===========================================\n",
      "train: epoch: 6, batch_id: 0, loss is: [0.10653888], accuracy is: [0.96875]\n",
      "train: epoch: 6, batch_id: 20, loss is: [0.2692457], accuracy is: [0.9375]\n",
      "train: epoch: 6, batch_id: 40, loss is: [0.14836423], accuracy is: [0.9453125]\n",
      "train: epoch: 6, batch_id: 60, loss is: [0.31164974], accuracy is: [0.9140625]\n",
      "train: epoch: 6, batch_id: 80, loss is: [0.08737734], accuracy is: [0.96875]\n",
      "===================================val===========================================\n",
      "validation: loss is: 0.14123289287090302, accuracy is: 0.9555084705352783\n",
      "===================================train===========================================\n",
      "train: epoch: 7, batch_id: 0, loss is: [0.13292007], accuracy is: [0.96875]\n",
      "train: epoch: 7, batch_id: 20, loss is: [0.19241312], accuracy is: [0.9296875]\n",
      "train: epoch: 7, batch_id: 40, loss is: [0.08458131], accuracy is: [0.96875]\n",
      "train: epoch: 7, batch_id: 60, loss is: [0.13493742], accuracy is: [0.953125]\n",
      "train: epoch: 7, batch_id: 80, loss is: [0.1931592], accuracy is: [0.9296875]\n",
      "===================================val===========================================\n",
      "validation: loss is: 0.12743274867534637, accuracy is: 0.9671609997749329\n",
      "===================================train===========================================\n",
      "train: epoch: 8, batch_id: 0, loss is: [0.10084306], accuracy is: [0.9609375]\n",
      "train: epoch: 8, batch_id: 20, loss is: [0.09640574], accuracy is: [0.96875]\n",
      "train: epoch: 8, batch_id: 40, loss is: [0.10779642], accuracy is: [0.9609375]\n",
      "train: epoch: 8, batch_id: 60, loss is: [0.12643482], accuracy is: [0.96875]\n",
      "train: epoch: 8, batch_id: 80, loss is: [0.19140013], accuracy is: [0.9453125]\n",
      "===================================val===========================================\n",
      "validation: loss is: 0.09421397000551224, accuracy is: 0.9719279408454895\n",
      "===================================train===========================================\n",
      "train: epoch: 9, batch_id: 0, loss is: [0.06287473], accuracy is: [0.9765625]\n",
      "train: epoch: 9, batch_id: 20, loss is: [0.11913891], accuracy is: [0.9609375]\n",
      "train: epoch: 9, batch_id: 40, loss is: [0.1325048], accuracy is: [0.953125]\n",
      "train: epoch: 9, batch_id: 60, loss is: [0.13647752], accuracy is: [0.96875]\n",
      "train: epoch: 9, batch_id: 80, loss is: [0.09159042], accuracy is: [0.9765625]\n",
      "===================================val===========================================\n",
      "validation: loss is: 0.22078344225883484, accuracy is: 0.929025411605835\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model = PointNet(num_classes=16, num_point=2048)\n",
    "    model.train()\n",
    "    optim = paddle.optimizer.Adam(parameters=model.parameters(), weight_decay=0.001)\n",
    "\n",
    "    epoch_num = 10\n",
    "    for epoch in range(epoch_num):\n",
    "        # train\n",
    "        print(\"===================================train===========================================\")\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            inputs, labels = data\n",
    "\n",
    "            predicts = model(inputs)\n",
    "            loss = F.nll_loss(predicts, labels)\n",
    "            acc = paddle.metric.accuracy(predicts, labels)        \n",
    "\n",
    "            if batch_id % 20 == 0: \n",
    "                print(\"train: epoch: {}, batch_id: {}, loss is: {}, accuracy is: {}\".format(epoch, batch_id, loss.numpy(), acc.numpy()))\n",
    "            \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.clear_grad()\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            paddle.save(model.state_dict(), './model/PointNet.pdparams')\n",
    "            paddle.save(optim.state_dict(), './model/PointNet.pdopt')\n",
    "        \n",
    "        # validation\n",
    "        print(\"===================================val===========================================\")\n",
    "        model.eval()\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "        for batch_id, data in enumerate(val_loader()):\n",
    "            inputs, labels = data\n",
    "\n",
    "            predicts = model(inputs)\n",
    "\n",
    "            loss = F.nll_loss(predicts, labels)\n",
    "            acc = paddle.metric.accuracy(predicts, labels)    \n",
    "            \n",
    "            losses.append(loss.numpy())\n",
    "            accuracies.append(acc.numpy())\n",
    "\n",
    "        avg_acc, avg_loss = np.mean(accuracies), np.mean(losses)\n",
    "        print(\"validation: loss is: {}, accuracy is: {}\".format(avg_loss, avg_acc))\n",
    "        model.train()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 五、评估与测试\n",
    "说明：通过`model.load_dict`的方式加载训练好的模型对测试集上的数据进行评估与测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: loss is: 0.14730410277843475, accuracy is: 0.9561118483543396\n"
     ]
    }
   ],
   "source": [
    "def evaluation():\r\n",
    "    model = PointNet()\r\n",
    "    model_state_dict = paddle.load('./model/PointNet.pdparams')\r\n",
    "    model.load_dict(model_state_dict)\r\n",
    "\r\n",
    "    model.eval()\r\n",
    "    accuracies = []\r\n",
    "    losses = []\r\n",
    "    for batch_id, data in enumerate(test_loader()):\r\n",
    "        inputs, labels = data\r\n",
    "\r\n",
    "        predicts = model(inputs)\r\n",
    "\r\n",
    "        loss = F.nll_loss(predicts, labels)\r\n",
    "        acc = paddle.metric.accuracy(predicts, labels)    \r\n",
    "        \r\n",
    "        losses.append(loss.numpy())\r\n",
    "        accuracies.append(acc.numpy())\r\n",
    "\r\n",
    "    avg_acc, avg_loss = np.mean(accuracies), np.mean(losses)\r\n",
    "    print(\"validation: loss is: {}, accuracy is: {}\".format(avg_loss, avg_acc))\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
