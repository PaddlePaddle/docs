{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72d769ce",
   "metadata": {},
   "source": [
    "# 模型组网\n",
    "\n",
    "飞桨的模型组网分为通过内置模型组网，通过 Sequential 组网和通过 SubClass 组网三种形式，下面通过前面使用的LeNet网络分别介绍这三种形式。\n",
    "\n",
    "## 通过内置模型组网\n",
    "\n",
    "飞桨在 [paddle.vision.models.LeNet](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/Overview_cn.html#about-models) 下内置了常用的分类模型，可以进行很方便的调用，通过下面的命令可以直接初始化一个LeNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c9d3513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2D(1, 6, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2D(kernel_size=2, stride=2, padding=0)\n",
      "    (3): Conv2D(6, 16, kernel_size=[5, 5], data_format=NCHW)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2D(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=120, dtype=float32)\n",
      "    (1): Linear(in_features=120, out_features=84, dtype=float32)\n",
      "    (2): Linear(in_features=84, out_features=10, dtype=float32)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "lenet = paddle.vision.models.LeNet(num_classes=10)\n",
    "print(lenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f8ac6",
   "metadata": {},
   "source": [
    "可以看到LeNet包含`features`和`fc`两个子网络，总共包含2个卷积层，2个ReLU激活层，2个MaxPool2D层，三个全链接层。\n",
    "\n",
    "## 通过 Sequential 组网\n",
    "\n",
    "针对顺序的线性网络结构,可以直接使用 [paddle.nn.Sequential](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Sequential_cn.html#sequential) 来快速完成组网，这种方式可以减少类的定义等代码编写。具体代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a86cc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2D(1, 6, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2D(kernel_size=2, stride=2, padding=0)\n",
      "  (3): Conv2D(6, 16, kernel_size=[5, 5], data_format=NCHW)\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2D(kernel_size=2, stride=2, padding=0)\n",
      "  (6): Linear(in_features=400, out_features=120, dtype=float32)\n",
      "  (7): Linear(in_features=120, out_features=84, dtype=float32)\n",
      "  (8): Linear(in_features=84, out_features=10, dtype=float32)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from paddle import nn\n",
    "\n",
    "lenet_Sequential = nn.Sequential(\n",
    "    nn.Conv2D(1, 6, 3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2D(2, 2),\n",
    "    nn.Conv2D(6, 16, 5, stride=1, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2D(2, 2),\n",
    "    nn.Linear(400, 120),\n",
    "    nn.Linear(120, 84), \n",
    "    nn.Linear(84, 10)\n",
    ")\n",
    "print(lenet_Sequential)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9524d1c",
   "metadata": {},
   "source": [
    "## 通过 SubClass 组网\n",
    "\n",
    "针对一些比较复杂的网络结构，就可以使用 SubClass 组网的方式来进行模型代码编写。通过 SubClass 组网进行组网需要完成下列三个步骤：\n",
    "1. 创建一个继承自[paddle.nn.Layer](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Layer_cn.html#layer)\n",
    "2. 在类的构造函数`__init__`中进行子Layer的定义，完成网络的构建\n",
    "3. 在类的`forward`函数中使用定义的子Layer进行前向计算。\n",
    "\n",
    "子Layer可以通过 基础API(卷积，池化或全连接)，Sequential 或 SubClass 的形式进行定义，子Layer在构造函数中一次定义后可在forward中多次调用。使用SubClass 组网形式实现LeNet的代码如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf89df53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2D(1, 6, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2D(kernel_size=2, stride=2, padding=0)\n",
      "    (3): Conv2D(6, 16, kernel_size=[5, 5], data_format=NCHW)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2D(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=120, dtype=float32)\n",
      "    (1): Linear(in_features=120, out_features=84, dtype=float32)\n",
      "    (2): Linear(in_features=84, out_features=10, dtype=float32)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LeNet(nn.Layer):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2D(\n",
    "                1, 6, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2D(2, 2),\n",
    "            nn.Conv2D(\n",
    "                6, 16, 5, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2D(2, 2))\n",
    "\n",
    "        if num_classes > 0:\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(400, 120),\n",
    "                nn.Linear(120, 84), nn.Linear(84, num_classes))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.features(inputs)\n",
    "\n",
    "        if self.num_classes > 0:\n",
    "            x = paddle.flatten(x, 1)\n",
    "            x = self.fc(x)\n",
    "        return x\n",
    "lenet_SubClass = LeNet()\n",
    "print(lenet_SubClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8843cf9c",
   "metadata": {},
   "source": [
    "## 飞桨内置基础API\n",
    "\n",
    "飞桨内置了大量基础的组网API，组网相关的API都在[paddle.nn](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Overview_cn.html#paddle-nn)目录下。组网相关的API类别与具体的API列表如下表：\n",
    "\n",
    "| 功能          | API名称                                                                   |\n",
    "| --- | ---|\n",
    "| Conv          | Conv1D、Conv2D、Conv3D、Conv1DTranspose、Conv2DTranspose、Conv3DTranspose |\n",
    "| Pool          | AdaptiveAvgPool1D、AdaptiveAvgPool2D、AdaptiveAvgPool3D、 AdaptiveMaxPool1D、AdaptiveMaxPool2D、AdaptiveMaxPool3D、 AvgPool1D、AvgPool2D、AvgPool3D、MaxPool1D、MaxPool2D、MaxPool3D          |\n",
    "| Padding       | Pad1D、Pad2D、Pad3D                                                       |\n",
    "| Activation    | ELU、GELU、Hardshrink、Hardtanh、HSigmoid、LeakyReLU、LogSigmoid、 LogSoftmax、PReLU、ReLU、ReLU6、SELU、Sigmoid、Softmax、Softplus、 Softshrink、Softsign、Tanh、Tanhshrink                                    |\n",
    "| Normlization  | BatchNorm、BatchNorm1D、BatchNorm2D、BatchNorm3D、GroupNorm、 InstanceNorm1D、InstanceNorm2D、InstanceNorm3D、LayerNorm、SpectralNorm、 SyncBatchNorm                                                             |\n",
    "| Recurrent NN  | BiRNN、GRU、GRUCell、LSTM、LSTMCell、RNN、RNNCellBase、SimpleRNN、SimpleRNNCell                    | \n",
    "| Transformer   | Transformer、TransformerDecoder、TransformerDecoderLayer、| TransformerEncoder、TransformerEncoderLayer |\n",
    "| Dropout       | AlphaDropout、Dropout、Dropout2d、Dropout3d                               |\n",
    "| Loss          | BCELoss、BCEWithLogitsLoss、CrossEntropyLoss、CTCLoss、KLDivLoss、L1Loss、 MarginRankingLoss、MSELoss、NLLLoss、SmoothL1Loss                         |\n",
    "\n",
    "## 模型的参数\n",
    "\n",
    "飞桨内置的 [paddle.summary](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/summary_cn.html#summary) 方法可以很方便的查看网络的基础结构，每层的输入输出shape和参数信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4617d646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "   Conv2D-5      [[64, 1, 28, 28]]     [64, 6, 28, 28]          60       \n",
      "    ReLU-5       [[64, 6, 28, 28]]     [64, 6, 28, 28]           0       \n",
      "  MaxPool2D-5    [[64, 6, 28, 28]]     [64, 6, 14, 14]           0       \n",
      "   Conv2D-6      [[64, 6, 14, 14]]     [64, 16, 10, 10]        2,416     \n",
      "    ReLU-6       [[64, 16, 10, 10]]    [64, 16, 10, 10]          0       \n",
      "  MaxPool2D-6    [[64, 16, 10, 10]]     [64, 16, 5, 5]           0       \n",
      "   Linear-7         [[64, 400]]           [64, 120]           48,120     \n",
      "   Linear-8         [[64, 120]]            [64, 84]           10,164     \n",
      "   Linear-9          [[64, 84]]            [64, 10]             850      \n",
      "===========================================================================\n",
      "Total params: 61,610\n",
      "Trainable params: 61,610\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 7.03\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 7.46\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 61610, 'trainable_params': 61610}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddle.summary(lenet, (64, 1, 28, 28))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
