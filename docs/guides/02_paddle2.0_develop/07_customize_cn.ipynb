{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e96f0c",
   "metadata": {},
   "source": [
    "# 自定义指标\n",
    "\n",
    "除了使用飞桨框架内置的指标外，飞桨框架还支持用户根据自己的实际场景，完成指标的自定义。\n",
    "\n",
    "## 一、自定义Loss\n",
    "\n",
    "有时你会遇到特定任务的Loss计算方式在框架既有的Loss接口中不存在，或算法不符合自己的需求，那么期望能够自己来进行Loss的自定义。这里介绍如何进行Loss的自定义操作，首先来看下面的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9958927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "\n",
    "class SelfDefineLoss(paddle.nn.Layer):\n",
    "   \"\"\"\n",
    "   1. 继承paddle.nn.Layer\n",
    "   \"\"\"\n",
    "   def __init__(self):\n",
    "       \"\"\"\n",
    "       2. 构造函数根据自己的实际算法需求和使用需求进行参数定义即可\n",
    "       \"\"\"\n",
    "       super().__init__()\n",
    "   \n",
    "   def forward(self, x, label):\n",
    "       \"\"\"\n",
    "       3. 实现forward函数，forward在调用时会传递两个参数：x和label\n",
    "           - x：单个或批次训练数据经过模型前向计算输出结果\n",
    "           - label：单个或批次训练数据对应的标签数据\n",
    "           接口返回值是一个Tensor，根据自定义的逻辑加和或计算均值后的损失\n",
    "       \"\"\"\n",
    "       # 使用Paddle中相关API自定义的计算逻辑\n",
    "       # output = xxxxx\n",
    "       # return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80390e85",
   "metadata": {},
   "source": [
    "接下来以交叉熵损失为例说明如何自定义损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6abeac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        loss = paddle.nn.functional.cross_entropy(\n",
    "            x,\n",
    "            label)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a431650",
   "metadata": {},
   "source": [
    "## 二、自定义Metric\n",
    "\n",
    "和Loss一样，你也可以来通过框架实现自定义的评估方法，具体的实现如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d27802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfDefineMetric(paddle.metric.Metric):\n",
    "    \"\"\"\n",
    "    1. 继承paddle.metric.Metric\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        2. 构造函数实现，自定义参数即可\n",
    "        \"\"\"\n",
    "        super(SelfDefineMetric, self).__init__()\n",
    "    \n",
    "    def name(self):\n",
    "        \"\"\"\n",
    "        3. 实现name方法，返回定义的评估指标名字\n",
    "        \"\"\"\n",
    "        # return '自定义评价指标的名字'\n",
    "    \n",
    "    def compute(self, **args):\n",
    "        \"\"\"\n",
    "        4. 本步骤可以省略，实现compute方法，这个方法主要用于`update`的加速，可以在这个方法中调用一些paddle实现好的Tensor计算API，编译到模型网络中一起使用低层C++ OP计算。\n",
    "        \"\"\"\n",
    "        # return '自己想要返回的数据，会做为update的参数传入。'\n",
    "    \n",
    "    def update(self, **args):\n",
    "        \"\"\"\n",
    "        5. 实现update方法，用于单个batch训练时进行评估指标计算。\n",
    "        - 当`compute`类函数未实现时，会将模型的计算输出和标签数据的展平作为`update`的参数传入。\n",
    "        - 当`compute`类函数做了实现时，会将compute的返回结果作为`update`的参数传入。\n",
    "        \"\"\"\n",
    "        # return acc_value\n",
    "    \n",
    "    def accumulate(self):\n",
    "        \"\"\"\n",
    "        6. 实现accumulate方法，返回历史batch训练积累后计算得到的评价指标值。\n",
    "        每次`update`调用时进行数据积累，`accumulate`计算时对积累的所有数据进行计算并返回。\n",
    "        结算结果会在`fit`接口的训练日志中呈现。\n",
    "        \"\"\"\n",
    "        # 利用update中积累的成员变量数据进行计算后返回\n",
    "        # return accumulated_acc_value\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        7. 实现reset方法，每个Epoch结束后进行评估指标的重置，这样下个Epoch可以重新进行计算。\n",
    "        \"\"\"\n",
    "        # do reset action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926454a0",
   "metadata": {},
   "source": [
    "接下来看一个框架中的具体例子，是框架中已提供的Accuracy计算接口，这里就是按照上述说明中的方法完成了实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "318b1aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy(paddle.metric.Metric):\n",
    "    def __init__(self, topk=(1, ), name=None, *args, **kwargs):\n",
    "        super(Accuracy, self).__init__(*args, **kwargs)\n",
    "        self.topk = topk\n",
    "        self.maxk = max(topk)\n",
    "        self._init_name(name)\n",
    "        self.reset()\n",
    "\n",
    "    def compute(self, pred, label, *args):\n",
    "        pred = paddle.argsort(pred, descending=True)\n",
    "        pred = paddle.slice(\n",
    "            pred, axes=[len(pred.shape) - 1], starts=[0], ends=[self.maxk])\n",
    "        if (len(label.shape) == 1) or \\\n",
    "           (len(label.shape) == 2 and label.shape[-1] == 1):\n",
    "            # In static mode, the real label data shape may be different\n",
    "            # from shape defined by paddle.static.InputSpec in model\n",
    "            # building, reshape to the right shape.\n",
    "            label = paddle.reshape(label, (-1, 1))\n",
    "        elif label.shape[-1] != 1:\n",
    "            # one-hot label\n",
    "            label = paddle.argmax(label, axis=-1, keepdim=True)\n",
    "        correct = pred == label\n",
    "        return paddle.cast(correct, dtype='float32')\n",
    "\n",
    "    def update(self, correct, *args):\n",
    "        if isinstance(correct, paddle.Tensor):\n",
    "            correct = correct.numpy()\n",
    "        num_samples = np.prod(np.array(correct.shape[:-1]))\n",
    "        accs = []\n",
    "        for i, k in enumerate(self.topk):\n",
    "            num_corrects = correct[..., :k].sum()\n",
    "            accs.append(float(num_corrects) / num_samples)\n",
    "            self.total[i] += num_corrects\n",
    "            self.count[i] += num_samples\n",
    "        accs = accs[0] if len(self.topk) == 1 else accs\n",
    "        return accs\n",
    "\n",
    "    def reset(self):\n",
    "        self.total = [0.] * len(self.topk)\n",
    "        self.count = [0] * len(self.topk)\n",
    "\n",
    "    def accumulate(self):\n",
    "        res = []\n",
    "        for t, c in zip(self.total, self.count):\n",
    "            r = float(t) / c if c > 0 else 0.\n",
    "            res.append(r)\n",
    "        res = res[0] if len(self.topk) == 1 else res\n",
    "        return res\n",
    "\n",
    "    def _init_name(self, name):\n",
    "        name = name or 'acc'\n",
    "        if self.maxk != 1:\n",
    "            self._name = ['{}_top{}'.format(name, k) for k in self.topk]\n",
    "        else:\n",
    "            self._name = [name]\n",
    "\n",
    "    def name(self):\n",
    "        return self._name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ad9fa9",
   "metadata": {},
   "source": [
    "## 三、自定义Callback\n",
    "\n",
    " `fit` 接口的callback参数支持传入一个 ` Callback` 类实例，用来在每轮训练和每个 ` batch` 训练前后进行调用，可以通过 ` callback` 收集到训练过程中的一些数据和参数，或者实现一些自定义操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a18a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfDefineCallback(paddle.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    1. 继承paddle.callbacks.Callback\n",
    "    2. 按照自己的需求实现以下类成员方法：\n",
    "        def on_train_begin(self, logs=None)                 训练开始前，`Model.fit`接口中调用\n",
    "        def on_train_end(self, logs=None)                   训练结束后，`Model.fit`接口中调用\n",
    "        def on_eval_begin(self, logs=None)                  评估开始前，`Model.evaluate`接口调用\n",
    "        def on_eval_end(self, logs=None)                    评估结束后，`Model.evaluate`接口调用\n",
    "        def on_predict_begin(self, logs=None)               预测测试开始前，`Model.predict`接口中调用\n",
    "        def on_predict_end(self, logs=None)                 预测测试结束后，`Model.predict`接口中调用\n",
    "        def on_epoch_begin(self, epoch, logs=None)          每轮训练开始前，`Model.fit`接口中调用\n",
    "        def on_epoch_end(self, epoch, logs=None)            每轮训练结束后，`Model.fit`接口中调用\n",
    "        def on_train_batch_begin(self, step, logs=None)     单个Batch训练开始前，`Model.fit`和`Model.train_batch`接口中调用\n",
    "        def on_train_batch_end(self, step, logs=None)       单个Batch训练结束后，`Model.fit`和`Model.train_batch`接口中调用\n",
    "        def on_eval_batch_begin(self, step, logs=None)      单个Batch评估开始前，`Model.evalute`和`Model.eval_batch`接口中调用\n",
    "        def on_eval_batch_end(self, step, logs=None)        单个Batch评估结束后，`Model.evalute`和`Model.eval_batch`接口中调用\n",
    "        def on_predict_batch_begin(self, step, logs=None)   单个Batch预测测试开始前，`Model.predict`和`Model.test_batch`接口中调用\n",
    "        def on_predict_batch_end(self, step, logs=None)     单个Batch预测测试结束后，`Model.predict`和`Model.test_batch`接口中调用\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    # 按照需求定义自己的类成员方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a392c",
   "metadata": {},
   "source": [
    "看两个框架中的实际例子。其中第一个例子时框架自带的 `ModelCheckpoint` 回调函数，可以在 `fit` 训练模型时自动存储每轮训练得到的模型；第二个例子是框架自带的 `ProgBarLogger` 回调函数,用于在 `fit` 训练时打印损失函数和评估指标。这两个回调函数会在 `fit` 执行时默认被调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c6e92b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCheckpoint(paddle.callbacks.Callback):\n",
    "    def __init__(self, save_freq=1, save_dir=None):\n",
    "        self.save_freq = save_freq\n",
    "        self.save_dir = save_dir\n",
    "   \n",
    "    def on_epoch_begin(self, epoch=None, logs=None):\n",
    "        self.epoch = epoch\n",
    "   \n",
    "    def _is_save(self):\n",
    "        return self.model and self.save_dir and ParallelEnv().local_rank == 0\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self._is_save() and self.epoch % self.save_freq == 0:\n",
    "            path = '{}/{}'.format(self.save_dir, epoch)\n",
    "            print('save checkpoint at {}'.format(os.path.abspath(path)))\n",
    "            self.model.save(path)\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        if self._is_save():\n",
    "            path = '{}/final'.format(self.save_dir)\n",
    "            print('save checkpoint at {}'.format(os.path.abspath(path)))\n",
    "            self.model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0384287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from paddle.distributed import ParallelEnv\n",
    "from paddle.utils import try_import\n",
    "from paddle.hapi.progressbar import ProgressBar\n",
    "\n",
    "class ProgBarLogger(paddle.callbacks.Callback):\n",
    "    def __init__(self, log_freq=1, verbose=2):\n",
    "        self.epochs = None\n",
    "        self.steps = None\n",
    "        self.progbar = None\n",
    "        self.verbose = verbose\n",
    "        self.log_freq = log_freq\n",
    "\n",
    "    def _is_print(self):\n",
    "        return self.verbose and ParallelEnv().local_rank == 0\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epochs = self.params['epochs']\n",
    "        assert self.epochs\n",
    "        self.train_metrics = self.params['metrics']\n",
    "        assert self.train_metrics\n",
    "\n",
    "        self._train_timer = {\n",
    "            'data_time': 0,\n",
    "            'batch_time': 0,\n",
    "            'count': 0,\n",
    "            'samples': 0,\n",
    "        }\n",
    "        if self._is_print():\n",
    "            print(\n",
    "                \"The loss value printed in the log is the current step, and the metric is the average value of previous steps.\"\n",
    "            )\n",
    "\n",
    "    def on_epoch_begin(self, epoch=None, logs=None):\n",
    "        self.steps = self.params['steps']\n",
    "        self.epoch = epoch\n",
    "        self.train_step = 0\n",
    "        if self.epochs and self._is_print():\n",
    "            print('Epoch %d/%d' % (epoch + 1, self.epochs))\n",
    "        self.train_progbar = ProgressBar(num=self.steps, verbose=self.verbose)\n",
    "\n",
    "        self._train_timer['batch_start_time'] = time.time()\n",
    "\n",
    "    def _updates(self, logs, mode):\n",
    "        values = []\n",
    "        metrics = getattr(self, '%s_metrics' % (mode))\n",
    "        progbar = getattr(self, '%s_progbar' % (mode))\n",
    "        steps = getattr(self, '%s_step' % (mode))\n",
    "\n",
    "        for k in metrics:\n",
    "            if k in logs:\n",
    "                values.append((k, logs[k]))\n",
    "\n",
    "        if self.verbose == 3 and hasattr(self, '_%s_timer' % (mode)):\n",
    "            timer = getattr(self, '_%s_timer' % (mode))\n",
    "            cnt = timer['count'] if timer['count'] > 0 else 1.0\n",
    "            samples = timer['samples'] if timer['samples'] > 0 else 1.0\n",
    "            values.append(\n",
    "                ('avg_reader_cost', \"%.5f sec\" % (timer['data_time'] / cnt)))\n",
    "            values.append(\n",
    "                ('avg_batch_cost', \"%.5f sec\" % (timer['batch_time'] / cnt)))\n",
    "            values.append(\n",
    "                ('ips', \"%.5f samples/sec\" %\n",
    "                 (samples / (timer['data_time'] + timer['batch_time']))))\n",
    "            timer['count'] = 0\n",
    "            timer['samples'] = 0\n",
    "            timer['data_time'] = 0.\n",
    "            timer['batch_time'] = 0.\n",
    "\n",
    "        progbar.update(steps, values)\n",
    "\n",
    "    def on_train_batch_begin(self, step, logs=None):\n",
    "        self._train_timer['batch_data_end_time'] = time.time()\n",
    "        self._train_timer['data_time'] += (\n",
    "            self._train_timer['batch_data_end_time'] -\n",
    "            self._train_timer['batch_start_time'])\n",
    "\n",
    "    def on_train_batch_end(self, step, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.train_step += 1\n",
    "\n",
    "        self._train_timer['batch_time'] += (\n",
    "            time.time() - self._train_timer['batch_data_end_time'])\n",
    "        self._train_timer['count'] += 1\n",
    "        samples = logs.get('batch_size', 1)\n",
    "        self._train_timer['samples'] += samples\n",
    "        if self._is_print() and self.train_step % self.log_freq == 0:\n",
    "            if self.steps is None or self.train_step < self.steps:\n",
    "                self._updates(logs, 'train')\n",
    "        self._train_timer['batch_start_time'] = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        if self._is_print() and (self.steps is not None):\n",
    "            self._updates(logs, 'train')\n",
    "\n",
    "    def on_eval_begin(self, logs=None):\n",
    "        self.eval_steps = logs.get('steps', None)\n",
    "        self.eval_metrics = logs.get('metrics', [])\n",
    "        self.eval_step = 0\n",
    "        self.evaled_samples = 0\n",
    "\n",
    "        self._eval_timer = {\n",
    "            'data_time': 0,\n",
    "            'batch_time': 0,\n",
    "            'count': 0,\n",
    "            'samples': 0,\n",
    "        }\n",
    "\n",
    "        self.eval_progbar = ProgressBar(\n",
    "            num=self.eval_steps, verbose=self.verbose)\n",
    "        if self._is_print():\n",
    "            print('Eval begin...')\n",
    "\n",
    "        self._eval_timer['batch_start_time'] = time.time()\n",
    "\n",
    "    def on_eval_batch_begin(self, step, logs=None):\n",
    "        self._eval_timer['batch_data_end_time'] = time.time()\n",
    "        self._eval_timer['data_time'] += (\n",
    "            self._eval_timer['batch_data_end_time'] -\n",
    "            self._eval_timer['batch_start_time'])\n",
    "\n",
    "    def on_eval_batch_end(self, step, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.eval_step += 1\n",
    "        samples = logs.get('batch_size', 1)\n",
    "        self.evaled_samples += samples\n",
    "\n",
    "        self._eval_timer['batch_time'] += (\n",
    "            time.time() - self._eval_timer['batch_data_end_time'])\n",
    "        self._eval_timer['count'] += 1\n",
    "        samples = logs.get('batch_size', 1)\n",
    "        self._eval_timer['samples'] += samples\n",
    "\n",
    "        if self._is_print() and self.eval_step % self.log_freq == 0:\n",
    "            if self.eval_steps is None or self.eval_step < self.eval_steps:\n",
    "                self._updates(logs, 'eval')\n",
    "\n",
    "        self._eval_timer['batch_start_time'] = time.time()\n",
    "\n",
    "    def on_predict_begin(self, logs=None):\n",
    "        self.test_steps = logs.get('steps', None)\n",
    "        self.test_metrics = logs.get('metrics', [])\n",
    "        self.test_step = 0\n",
    "        self.tested_samples = 0\n",
    "\n",
    "        self._test_timer = {\n",
    "            'data_time': 0,\n",
    "            'batch_time': 0,\n",
    "            'count': 0,\n",
    "            'samples': 0,\n",
    "        }\n",
    "\n",
    "        self.test_progbar = ProgressBar(\n",
    "            num=self.test_steps, verbose=self.verbose)\n",
    "        if self._is_print():\n",
    "            print('Predict begin...')\n",
    "\n",
    "        self._test_timer['batch_start_time'] = time.time()\n",
    "\n",
    "    def on_predict_batch_begin(self, step, logs=None):\n",
    "        self._test_timer['batch_data_end_time'] = time.time()\n",
    "        self._test_timer['data_time'] += (\n",
    "            self._test_timer['batch_data_end_time'] -\n",
    "            self._test_timer['batch_start_time'])\n",
    "\n",
    "    def on_predict_batch_end(self, step, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.test_step += 1\n",
    "        samples = logs.get('batch_size', 1)\n",
    "        self.tested_samples += samples\n",
    "\n",
    "        self._test_timer['batch_time'] += (\n",
    "            time.time() - self._test_timer['batch_data_end_time'])\n",
    "        self._test_timer['count'] += 1\n",
    "        samples = logs.get('batch_size', 1)\n",
    "        self._test_timer['samples'] += samples\n",
    "\n",
    "        if self.test_step % self.log_freq == 0 and self._is_print():\n",
    "            if self.test_steps is None or self.test_step < self.test_steps:\n",
    "                self._updates(logs, 'test')\n",
    "\n",
    "        self._test_timer['batch_start_time'] = time.time()\n",
    "\n",
    "    def on_eval_end(self, logs=None):\n",
    "        logs = logs or {}\n",
    "        if self._is_print() and (self.eval_steps is not None):\n",
    "            self._updates(logs, 'eval')\n",
    "            print('Eval samples: %d' % (self.evaled_samples))\n",
    "\n",
    "    def on_predict_end(self, logs=None):\n",
    "        logs = logs or {}\n",
    "        if self._is_print():\n",
    "            if self.test_step % self.log_freq != 0 or self.verbose == 1:\n",
    "                self._updates(logs, 'test')\n",
    "            print('Predict samples: %d' % (self.tested_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7d7f04",
   "metadata": {},
   "source": [
    "## 四、自定义指标的使用\n",
    "\n",
    "接下来以mnist为例，使用自定义的指标替换框架中的指标，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2a66f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1223 04:29:17.810079  9910 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.2, Runtime API Version: 10.2\n",
      "W1223 04:29:17.815956  9910 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/5\n",
      "step   2/938 [..............................] - loss: 2.1375 - acc: 0.1562 - ETA: 7:27 - 478ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 938/938 [==============================] - loss: 0.1039 - acc: 0.9303 - 138ms/step          \n",
      "Epoch 2/5\n",
      "step 938/938 [==============================] - loss: 0.0887 - acc: 0.9696 - 123ms/step          \n",
      "Epoch 3/5\n",
      "step 938/938 [==============================] - loss: 0.0285 - acc: 0.9782 - 158ms/step          \n",
      "Epoch 4/5\n",
      "step 938/938 [==============================] - loss: 0.0049 - acc: 0.9833 - 158ms/step          \n",
      "Epoch 5/5\n",
      "step 938/938 [==============================] - loss: 0.1041 - acc: 0.9863 - 145ms/step          \n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import numpy as np\n",
    "from paddle.vision.transforms import ToTensor\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=ToTensor())\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=ToTensor())\n",
    "\n",
    "mnist = paddle.nn.Sequential(\n",
    "    paddle.nn.Flatten(1, -1), \n",
    "    paddle.nn.Linear(784, 512), \n",
    "    paddle.nn.ReLU(), \n",
    "    paddle.nn.Dropout(0.2), \n",
    "    paddle.nn.Linear(512, 10)\n",
    ")\n",
    "\n",
    "model = paddle.Model(mnist)\n",
    "\n",
    "# 将paddle.nn.CrossEntropyLoss替换为CrossEntropy，\n",
    "# 将paddle.metric.Accuracy替换为Accuracy\n",
    "model.prepare(optimizer=paddle.optimizer.Adam(parameters=model.parameters()), \n",
    "              loss=CrossEntropy(), \n",
    "              metrics=Accuracy())\n",
    "\n",
    "# 启动模型训练，加入自定义的两个Callbacks\n",
    "model.fit(train_dataset, \n",
    "          epochs=5, \n",
    "          batch_size=64, \n",
    "          verbose=0, \n",
    "          callbacks=[ProgBarLogger(verbose=1), ModelCheckpoint()]\n",
    "         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
