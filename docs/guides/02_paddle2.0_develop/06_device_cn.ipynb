{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd536a25",
   "metadata": {},
   "source": [
    "# 单机多卡训练\n",
    "\n",
    "飞桨框架2.0增加 [paddle.distributed.spawn](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/distributed/spawn_cn.html) 函数来启动单机多卡训练，同时原有的 [paddle.distributed.launch](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/distributed/launch_cn.html) 的方式依然保留。\n",
    "\n",
    "## 一、launch启动\n",
    "\n",
    "### 1.1 高层API场景\n",
    "\n",
    "当调用 [paddle.Model](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/Model_cn.html) 高层API来实现训练时，想要启动单机多卡训练非常简单，代码不需要做任何修改，只需要在启动时增加一下参数 `-m paddle.distributed.launch` 。\n",
    "使用高层API的训练代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2702a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import numpy as np\n",
    "from paddle.vision.transforms import ToTensor\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=ToTensor())\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=ToTensor())\n",
    "\n",
    "mnist = paddle.nn.Sequential(\n",
    "    paddle.nn.Flatten(1, -1), \n",
    "    paddle.nn.Linear(784, 512), \n",
    "    paddle.nn.ReLU(), \n",
    "    paddle.nn.Dropout(0.2), \n",
    "    paddle.nn.Linear(512, 10)\n",
    ")\n",
    "\n",
    "model = paddle.Model(mnist)\n",
    "\n",
    "model.prepare(optimizer=paddle.optimizer.Adam(parameters=model.parameters()), \n",
    "              loss=paddle.nn.CrossEntropyLoss(), \n",
    "              metrics=paddle.metric.Accuracy())\n",
    "\n",
    "model.fit(train_dataset, \n",
    "          epochs=5, \n",
    "          batch_size=64,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c28b9",
   "metadata": {},
   "source": [
    "将上述代码保存为train.py，使用高层API启动多卡训练的命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db288b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单机单卡启动，默认使用第0号卡\n",
    "! python train.py\n",
    "# 单机多卡启动，默认使用当前可见的所有卡\n",
    "! python -m paddle.distributed.launch train.py\n",
    "# 单机多卡启动，设置当前使用的第0号和第1号卡\n",
    "! python -m paddle.distributed.launch --gpus='0,1' train.py\n",
    "# 单机多卡启动，设置当前使用第0号和第1号卡\n",
    "! export CUDA_VISIBLE_DEVICES=0,1\n",
    "! python -m paddle.distributed.launch train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17552b14",
   "metadata": {},
   "source": [
    "### 1.2 基础API场景\n",
    "\n",
    "如果使用基础API实现现训练，想要启动单机多卡训练，需要对单机单卡的代码进行3处修改，具体如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebc36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddle.vision.transforms import ToTensor\n",
    "# 第1处改动 导入分布式训练所需的包\n",
    "import paddle.distributed as dist\n",
    "# 加载数据集\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=ToTensor())\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=ToTensor())\n",
    "# 第2处改动，初始化并行环境\n",
    "dist.init_parallel_env()\n",
    "\n",
    "# 定义网络结构\n",
    "mnist = paddle.nn.Sequential(\n",
    "    paddle.nn.Flatten(1, -1),\n",
    "    paddle.nn.Linear(784, 512),\n",
    "    paddle.nn.ReLU(),\n",
    "    paddle.nn.Dropout(0.2),\n",
    "    paddle.nn.Linear(512, 10)\n",
    ")\n",
    "# 用 DataLoader 实现数据加载\n",
    "train_loader = paddle.io.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 第3处改动，增加paddle.DataParallel封装\n",
    "mnist = paddle.DataParallel(mnist)\n",
    "mnist.train()\n",
    "# 设置迭代次数\n",
    "epochs = 5\n",
    "# 设置优化器\n",
    "optim = paddle.optimizer.Adam(parameters=mnist.parameters())\n",
    "for epoch in range(epochs):\n",
    "    for batch_id, data in enumerate(train_loader()):\n",
    "        x_data = data[0]            # 训练数据\n",
    "        y_data = data[1]            # 训练数据标签\n",
    "        predicts = mnist(x_data)    # 预测结果\n",
    "        # 计算损失 等价于 prepare 中loss的设置\n",
    "        loss = paddle.nn.functional.cross_entropy(predicts, y_data)\n",
    "        # 计算准确率 等价于 prepare 中metrics的设置\n",
    "        acc = paddle.metric.accuracy(predicts, y_data)\n",
    "        # 下面的反向传播、打印训练信息、更新参数、梯度清零都被封装到 Model.fit() 中\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        if (batch_id+1) % 1800 == 0:\n",
    "            print(\"epoch: {}, batch_id: {}, loss is: {}, acc is: {}\".format(epoch, batch_id, loss.numpy(), acc.numpy()))\n",
    "        # 更新参数\n",
    "        optim.step()\n",
    "        # 梯度清零\n",
    "        optim.clear_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa5a5e",
   "metadata": {},
   "source": [
    "修改完后保存文件为train.py，然后使用跟高层API相同的启动方式即可。\n",
    "**注意：** 单卡训练不支持调用 `init_parallel_env` ，请使用以下几种方式进行分布式训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56786ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单机多卡启动，默认使用当前可见的所有卡\n",
    "! python -m paddle.distributed.launch train.py\n",
    "# 单机多卡启动，设置当前使用的第0号和第1号卡\n",
    "! python -m paddle.distributed.launch --gpus '0,1' train.py\n",
    "# 单机多卡启动，设置当前使用第0号和第1号卡\n",
    "! export CUDA_VISIBLE_DEVICES=0,1\n",
    "! python -m paddle.distributed.launch train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5045368",
   "metadata": {},
   "source": [
    "## 二、spawn启动\n",
    "\n",
    " `launch` 方式启动训练，以文件为单位启动多进程，需要用户在启动时调用 `paddle.distributed.launch` ，对于进程的管理要求较高。飞桨框架2.0版本增加了 `spawn` 启动方式，可以更好地控制进程，在日志打印、训练退出时更友好。使用示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbcdcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.optimizer as opt\n",
    "import paddle.distributed as dist\n",
    "\n",
    "class LinearNet(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self._linear1 = nn.Linear(10, 10)\n",
    "        self._linear2 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._linear2(self._linear1(x))\n",
    "\n",
    "def train(print_result=False):\n",
    "\n",
    "    # 1. 初始化并行训练环境\n",
    "    dist.init_parallel_env()\n",
    "\n",
    "    # 2. 创建并行训练 Layer 和 Optimizer\n",
    "    layer = LinearNet()\n",
    "    dp_layer = paddle.DataParallel(layer)\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    adam = opt.Adam(\n",
    "        learning_rate=0.001, parameters=dp_layer.parameters())\n",
    "\n",
    "    # 3. 运行网络\n",
    "    inputs = paddle.randn([10, 10], 'float32')\n",
    "    outputs = dp_layer(inputs)\n",
    "    labels = paddle.randn([10, 1], 'float32')\n",
    "    loss = loss_fn(outputs, labels)\n",
    "\n",
    "    if print_result is True:\n",
    "        print(\"loss:\", loss.numpy())\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    adam.step()\n",
    "    adam.clear_grad()\n",
    "\n",
    "# 传入训练函数、参数、指定进程数并指定当前使用的卡号\n",
    "if __name__ == '__main__':\n",
    "    dist.spawn(train, args=(True,), nprocs=2, gpus='4,5')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea540e08",
   "metadata": {},
   "source": [
    "上述代码在本地运行结果如下：\n",
    "init nccl context nranks: 2 local rank: 0 gpu id: 4 ring id: 0\n",
    "init nccl context nranks: 2 local rank: 1 gpu id: 5 ring id: 0\n",
    "Please NOTE: device: 5, GPU Compute Capability: 7.0, Driver API Version: 10.2, Runtime API Version: 10.2\n",
    "Please NOTE: device: 4, GPU Compute Capability: 7.0, Driver API Version: 10.2, Runtime API Version: 10.2\n",
    "device: 4, cuDNN Version: 7.6.\n",
    "device: 5, cuDNN Version: 7.6.\n",
    "loss: [2.041318]\n",
    "loss: [4.749344]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47c613",
   "metadata": {},
   "source": [
    "调用 [paddle.distributed.spawn](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/distributed/spawn_cn.html) 来启动多卡训练时，可根据需要设置参数：\n",
    "* func：由 spawn 方法启动的进程所调用的目标函数。\n",
    "* args：传入目标函数 func 的参数。\n",
    "* nprocs：启动进程的数目。当仅需要使用部分可见的GPU设备进行训练时，可设置该参数指定GPU数。例如：当前机器有8张GPU卡 {0,1,2,3,4,5,6,7}，此时会使用前两张卡 {0,1}；或者当前机器通过配置环境变量 CUDA_VISIBLE_DEVICES=4,5,6,7，仅使4张GPU卡可见，此时会使用可见的前两张卡 {4,5}。若不设置该参数，默认使用所有可见的GPU设备训练。\n",
    "* gpus：指定训练使用的GPU ID。例如 gpus='4,5' 可指定使用第4号卡和第5号卡。若不设置该参数，默认使用GPU ID序号较小的GPU。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
