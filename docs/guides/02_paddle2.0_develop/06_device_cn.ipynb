{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd536a25",
   "metadata": {},
   "source": [
    "# 单机多卡训练\n",
    "\n",
    "随着深度学习的发展，模型和数据集越来越大，有时单张显卡无法满足训练任务的显存要求，或者单卡训练用时太久，影响训练速度，这些情况下需要用到多卡训练的方式。飞桨框架 2.0 增加 [paddle.distributed.spawn](../api/paddle/distributed/spawn_cn.html) 函数来启动单机多卡训练，同时原有的 [paddle.distributed.launch](../api/paddle/distributed/launch_cn.html) 的方式依然保留。\n",
    "\n",
    "## 一、launch启动\n",
    "\n",
    "### 1.1 高层API场景\n",
    "\n",
    "当调用 [paddle.Model](../api/paddle/Model_cn.html) 高层API来实现训练时，想要启动单机多卡训练非常简单，代码不需要做任何修改，只需要在启动时增加一下参数 `-m paddle.distributed.launch` 。\n",
    "以MNIST为例，使用高层API的训练代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2702a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import numpy as np\n",
    "from paddle.vision.transforms import ToTensor\n",
    "\n",
    "# 加载训练数据集和测试数据集\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=ToTensor())\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=ToTensor())\n",
    "\n",
    "# 使用 Sequential 模型组网\n",
    "mnist = paddle.nn.Sequential(\n",
    "    paddle.nn.Flatten(1, -1), \n",
    "    paddle.nn.Linear(784, 512), \n",
    "    paddle.nn.ReLU(), \n",
    "    paddle.nn.Dropout(0.2), \n",
    "    paddle.nn.Linear(512, 10)\n",
    ")\n",
    "\n",
    "# 使用 paddle.Model 封装模型\n",
    "model = paddle.Model(mnist)\n",
    "\n",
    "# 使用 Model.prepare 配置训练准备参数\n",
    "model.prepare(optimizer=paddle.optimizer.Adam(parameters=model.parameters()), \n",
    "              loss=paddle.nn.CrossEntropyLoss(), \n",
    "              metrics=paddle.metric.Accuracy())\n",
    "\n",
    "# 使用 Model.fit 训练模型\n",
    "model.fit(train_dataset, \n",
    "          epochs=5, \n",
    "          batch_size=64,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c28b9",
   "metadata": {},
   "source": [
    "将上述代码保存为train.py，使用高层API启动多卡训练的命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db288b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 单机单卡启动，默认使用第0号卡\n",
    "! python train.py\n",
    "# 单机多卡启动，默认使用当前可见的所有卡\n",
    "! python -m paddle.distributed.launch train.py\n",
    "# 单机多卡启动，设置当前使用的第0号和第1号卡\n",
    "! python -m paddle.distributed.launch --gpus='0,1' train.py\n",
    "# 单机多卡启动，设置当前使用第0号和第1号卡\n",
    "! export CUDA_VISIBLE_DEVICES=0,1\n",
    "! python -m paddle.distributed.launch train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc2fdc-795d-400b-8f40-a69d88595558",
   "metadata": {},
   "source": [
    "这里补充一段介绍这个方式启动后发生了什么？任务怎么分配到不同卡上的\n",
    "另外针对这里应该会有常见的问题定位流程，补充一下介绍，有FAQ可以补一下到FAQ的链接。\n",
    "\n",
    "（待补充）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17552b14",
   "metadata": {},
   "source": [
    "### 1.2 基础API场景\n",
    "\n",
    "如果使用基础API实现现训练，想要启动单机多卡训练，需要对单机单卡的代码进行3处修改，具体如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebc36a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddle.vision.transforms import ToTensor\n",
    "# 第1处改动，导入分布式训练所需的包\n",
    "import paddle.distributed as dist\n",
    "# 加载数据集\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=ToTensor())\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=ToTensor())\n",
    "# 第2处改动，初始化并行环境\n",
    "dist.init_parallel_env()\n",
    "\n",
    "# 定义网络结构\n",
    "mnist = paddle.nn.Sequential(\n",
    "    paddle.nn.Flatten(1, -1),\n",
    "    paddle.nn.Linear(784, 512),\n",
    "    paddle.nn.ReLU(),\n",
    "    paddle.nn.Dropout(0.2),\n",
    "    paddle.nn.Linear(512, 10)\n",
    ")\n",
    "# 用 DataLoader 实现数据加载\n",
    "train_loader = paddle.io.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 第3处改动，增加paddle.DataParallel封装\n",
    "mnist = paddle.DataParallel(mnist)\n",
    "mnist.train()\n",
    "# 设置迭代次数\n",
    "epochs = 5\n",
    "# 设置优化器\n",
    "optim = paddle.optimizer.Adam(parameters=mnist.parameters())\n",
    "for epoch in range(epochs):\n",
    "    for batch_id, data in enumerate(train_loader()):\n",
    "        x_data = data[0]            # 训练数据\n",
    "        y_data = data[1]            # 训练数据标签\n",
    "        predicts = mnist(x_data)    # 预测结果\n",
    "        # 计算损失 等价于 prepare 中loss的设置\n",
    "        loss = paddle.nn.functional.cross_entropy(predicts, y_data)\n",
    "        # 计算准确率 等价于 prepare 中metrics的设置\n",
    "        acc = paddle.metric.accuracy(predicts, y_data)\n",
    "        # 下面的反向传播、打印训练信息、更新参数、梯度清零都被封装到 Model.fit() 中\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        if (batch_id+1) % 1800 == 0:\n",
    "            print(\"epoch: {}, batch_id: {}, loss is: {}, acc is: {}\".format(epoch, batch_id, loss.numpy(), acc.numpy()))\n",
    "        # 更新参数\n",
    "        optim.step()\n",
    "        # 梯度清零\n",
    "        optim.clear_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa5a5e",
   "metadata": {},
   "source": [
    "修改完后保存文件为train.py，然后使用跟高层API相同的启动方式即可。\n",
    "\n",
    "补充：\n",
    "\n",
    "这里基础API实现的效果和高层一模一样吗？完全没有差异？有没有基础API可以更灵活应用的场景？为什么高层不用补额外的配置代码？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56786ff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 单机多卡启动，默认使用当前可见的所有卡\n",
    "! python -m paddle.distributed.launch train.py\n",
    "# 单机多卡启动，设置当前使用的第0号和第1号卡\n",
    "! python -m paddle.distributed.launch --gpus '0,1' train.py\n",
    "# 单机多卡启动，设置当前使用第0号和第1号卡\n",
    "! export CUDA_VISIBLE_DEVICES=0,1\n",
    "! python -m paddle.distributed.launch train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5045368",
   "metadata": {},
   "source": [
    "## 二、spawn启动\n",
    "\n",
    " `launch` 方式启动训练，以文件为单位启动多进程，需要用户在启动时调用 `paddle.distributed.launch` ，对于进程的管理要求较高。飞桨框架2.0版本增加了 `spawn` 启动方式，可以更好地控制进程，在日志打印、训练退出时更友好。\n",
    " \n",
    "（补充“对进程的管理要求较高”、“可以更好地控制进程，在日志打印、训练退出时更友好”这几句话的理解）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199558fc-9c58-4ff5-8e9e-1bbddab9662d",
   "metadata": {},
   "source": [
    "### 2.1 高层API场景\n",
    "\n",
    "使用 `spawn` 方式启动多卡训练时，需要先将训练的过程封装成一个函数，将超参数设为该函数的参数传入训练流程中。代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed54b0d-dcbb-4c52-b2aa-63bae432d79a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import numpy as np\n",
    "from paddle.vision.transforms import ToTensor\n",
    "# 高层API场景使用spwan方式时，需要导入paddle.distributed包\n",
    "import paddle.distributed as dist\n",
    "\n",
    "def train():\n",
    "    # 加载训练数据集和测试数据集\n",
    "    train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=ToTensor())\n",
    "    test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=ToTensor())\n",
    "\n",
    "    # 使用 Sequential 模型组网\n",
    "    mnist = paddle.nn.Sequential(\n",
    "        paddle.nn.Flatten(1, -1), \n",
    "        paddle.nn.Linear(784, 512), \n",
    "        paddle.nn.ReLU(), \n",
    "        paddle.nn.Dropout(0.2), \n",
    "        paddle.nn.Linear(512, 10)\n",
    "    )\n",
    "\n",
    "    # 使用 paddle.Model 封装模型\n",
    "    model = paddle.Model(mnist)\n",
    "\n",
    "    # 使用 Model.prepare 配置训练准备参数\n",
    "    model.prepare(optimizer=paddle.optimizer.Adam(parameters=model.parameters()), \n",
    "                  loss=paddle.nn.CrossEntropyLoss(), \n",
    "                  metrics=paddle.metric.Accuracy())\n",
    "\n",
    "    # 使用 Model.fit 训练模型\n",
    "    model.fit(train_dataset, \n",
    "              epochs=5, \n",
    "              batch_size=64,\n",
    "              verbose=1)\n",
    "\n",
    "\n",
    "# 传入训练函数，指定进程数并指定当前使用的卡号\n",
    "# （这里我测试使用多卡会报错，只能单卡跑）\n",
    "if __name__ == '__main__':\n",
    "    dist.spawn(train, nprocs=1, gpus='0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae28fc-5084-4393-a622-cf60d5e9df00",
   "metadata": {},
   "source": [
    "### 2.2 基础API场景\n",
    "\n",
    "与高层API场景类似，使用 `spawn` 方式启动多卡训练时，需要先将训练的过程封装成一个函数，将超参数设为该函数的参数传入训练流程中。同时，也需要与 `paddle.distributed.launch` 过程类似，进行三处改动：导入分布式包、初始化并行环境和将模型封装。具体代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbcdcdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.optimizer as opt\n",
    "# 第1处改动，导入分布式训练所需的包\n",
    "import paddle.distributed as dist\n",
    "\n",
    "def train(print_result=False):\n",
    "    # 加载数据集\n",
    "    train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=ToTensor())\n",
    "    test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=ToTensor())\n",
    "    # 第2处改动，初始化并行环境\n",
    "    dist.init_parallel_env()\n",
    "\n",
    "    # 定义网络结构\n",
    "    mnist = paddle.nn.Sequential(\n",
    "        paddle.nn.Flatten(1, -1),\n",
    "        paddle.nn.Linear(784, 512),\n",
    "        paddle.nn.ReLU(),\n",
    "        paddle.nn.Dropout(0.2),\n",
    "        paddle.nn.Linear(512, 10)\n",
    "    )\n",
    "    # 用 DataLoader 实现数据加载\n",
    "    train_loader = paddle.io.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # 第3处改动，增加paddle.DataParallel封装\n",
    "    mnist = paddle.DataParallel(mnist)\n",
    "    mnist.train()\n",
    "    # 设置迭代次数\n",
    "    epochs = 5\n",
    "    # 设置优化器\n",
    "    optim = paddle.optimizer.Adam(parameters=mnist.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            x_data = data[0]            # 训练数据\n",
    "            y_data = data[1]            # 训练数据标签\n",
    "            predicts = mnist(x_data)    # 预测结果\n",
    "            # 计算损失 等价于 prepare 中loss的设置\n",
    "            loss = paddle.nn.functional.cross_entropy(predicts, y_data)\n",
    "            # 计算准确率 等价于 prepare 中metrics的设置\n",
    "            acc = paddle.metric.accuracy(predicts, y_data)\n",
    "            # 下面的反向传播、打印训练信息、更新参数、梯度清零都被封装到 Model.fit() 中\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            if (batch_id+1) % 1800 == 0 and print_reslut:\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {}, acc is: {}\".format(epoch, batch_id, loss.numpy(), acc.numpy()))\n",
    "            # 更新参数\n",
    "            optim.step()\n",
    "            # 梯度清零\n",
    "            optim.clear_grad()\n",
    "\n",
    "# 传入训练函数、参数、指定进程数并指定当前使用的卡号\n",
    "if __name__ == '__main__':\n",
    "    dist.spawn(train, args=(True,), nprocs=2, gpus='4,5')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea540e08",
   "metadata": {},
   "source": [
    "上述代码在本地运行结果如下：\n",
    "init nccl context nranks: 2 local rank: 0 gpu id: 4 ring id: 0\n",
    "init nccl context nranks: 2 local rank: 1 gpu id: 5 ring id: 0\n",
    "Please NOTE: device: 5, GPU Compute Capability: 7.0, Driver API Version: 10.2, Runtime API Version: 10.2\n",
    "Please NOTE: device: 4, GPU Compute Capability: 7.0, Driver API Version: 10.2, Runtime API Version: 10.2\n",
    "device: 4, cuDNN Version: 7.6.\n",
    "device: 5, cuDNN Version: 7.6.\n",
    "loss: [2.041318]\n",
    "loss: [4.749344]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47c613",
   "metadata": {},
   "source": [
    "调用 [paddle.distributed.spawn](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/distributed/spawn_cn.html) 来启动多卡训练时，可根据需要设置参数：\n",
    "* func：由 spawn 方法启动的进程所调用的目标函数。\n",
    "* args：传入目标函数 func 的参数。\n",
    "* nprocs：启动进程的数目。当仅需要使用部分可见的GPU设备进行训练时，可设置该参数指定GPU数。例如：当前机器有8张GPU卡 {0,1,2,3,4,5,6,7}，此时会使用前两张卡 {0,1}；或者当前机器通过配置环境变量 CUDA_VISIBLE_DEVICES=4,5,6,7，仅使4张GPU卡可见，此时会使用可见的前两张卡 {4,5}。若不设置该参数，默认使用所有可见的GPU设备训练。\n",
    "* gpus：指定训练使用的GPU ID。例如 gpus='4,5' 可指定使用第4号卡和第5号卡。若不设置该参数，默认使用GPU ID序号较小的GPU。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132576e-7021-4fcc-a56d-d5ecb4bccebd",
   "metadata": {},
   "source": [
    "# 三、总结\n",
    "\n",
    "待补充"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
